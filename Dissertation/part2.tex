\chapter{Решение обратной задачи в пространстве матриц кросс-спектральной плотности} \label{chapt2}

% План.
% Методы решения обратной задачи для МЭГ/ЭЭГ.
% Сканирующий подход. Нахождение ориентации диполя.
% MUSIC, RAP-MUSIC, бимформеры. Сканирующие методы решения обратной задачи для анализа коннективностей.
% Алгоритм DICS. Модификация DICS для оценки imcoh в пр-ве источников. Wedge MUSIC.
% Методы глолбальной оптимизации.
% Оценка активностей при помощи псевдообратной матрицы.
% Априорная информация о структуре решения. MNE, MinimumCurrent, mxNormMNE.
% Адаптация MxNormMNE к решению обратной задачи для поиска синхронностей.
% Техники ускорения расчета и оптимизации вычислительных ресурсов.
% Active set и связь с MUSIC.
% Критерий останова алгоритма.
% Сокращение размерности пр-ва сенсоров.

\section{Введение}

В предыдущей главе нами была получена система уравнений, связывающая
коэффициенты матрицы кросс-спектральной плотности мощности в пространстве
источников с аналогичными коэффициентами в пространстве сенсоров. Хотя это
уравнение и является линейными относительно неизвестных величин $c_{ij}^{ss}$,
процедура нахождения решения, которое адекватно описывало бы поведение реальных
систем, осложнено тем фактом, что рассматриваемая система уравнений существенно
недоопределена, а следовательно для нее существует бесконечное количество
решений, далеко не все из которых осуществимы для реальных систем
взаимодействующих нейронных ансамблей.

Вообще, система уравнений~\ref{eq:cp_final_re_im} для фиксированных ориентаций
диполей по своей структуре ничем кроме шумового слагаемого не отличается от
систем~\ref{eq:BV_generative_matrix}.
Система уравнений~\ref{eq:BV_generative_matrix} на неизвестные величины $\mathcal{Q}$ также
является линейной и недоопределенной. Некоторые отличия возникают лишь при
рассмотрении свободно ориентированных диполей.

Задачу оценки величин, положений и ориентаций токовых диполей $\mathcal{Q}$ на
основании измерений $\mathcal{B}, \mathcal{V}$ в электрофизиологии принятно
называть \emph{обратной задачей} МЭГ/ЭЭГ.  Как и в случае оценки
кросс-спектральных коэффициентов, решение обратной задачи МЭГ/ЭЭГ не
единственно.  Для выбора какого-либо одного решения $\mathcal{Q}$ по коре
применяют различные эвристики, ограничивающие выбор из бесконечного множества
возможных вариантов.  Как правило, получающееся решение отвечает тому или иному
критерию оптимальности в соответствии с используемой эвристикой, при условии,
что предположения модели выполняются.  Во введении к этой главе мы рассмотрим
основные методы решения обратной задачи для поиска активных токовых диполей на
коре, а затем перейдем к рассмотрению методик для оценки кросс-спектральных
коэффициентов с учетом свободной ориентации.

Все существующие методики решения обратной задачи МЭГ/ЭЭГ можно условно
разделить на два класса.
К первому классу относятся алгоритмы, основанные на
поиске заранее заданного числа эквивалентных токовых диполей, объясняющих измерения
наилучшим образом. При этом оцениваются положения и ориентации этих диполей.
К этому классу относится необходимый нам для дальнейшего изложения алгоритм % Так ли это?
MUSIC (multiple signal classification), а также его модификация RAP-MUSIC
(recursively applied and projected MUSIC), которые условно можно назвать сканирующими.

Второй класс алгоритмов, называемых в литературе <<имиджинговыми>>, ставит задачу
отыскания активности, распределенной сразу по всей коре. Ко второй группе методов
можно условно отнести методы оптимальной пространственной фильтрации, которые
восстанавливают сигнал отдельно для каждой выбранной точки коры в соответствии
с неким локальным критерием оптимальности, а также методы, основанные на выборе
решения с минимальной нормой.

Суть подхода оптимальной фильтрации состоит в том, что для
фиксированной точки внутри объема мозга ставится задача нахождения
пространственного фильтра, оптимизирующего определенную характеристику сигнала,
восстанавливаемого при помощи этого фильтра. В качестве такой характеристики
может выступать, например, отношение сигнал/шум, или же мы можем
руководствоваться критерием минимизации протечки сигнала от других источников в
точку, в которой мы хотим восстановить активность.  Здесь важно отметить, что
конкретный вид решения, полученного в результате оптимизации выбранного
функционала качества будет зависить также от предполагаемой пространственной
структуры шума.

Отметим, что структура восстановленной после применения совокупности найденных
фильтров активации на коре при таком подходе, вообще говоря, субоптимальна с
точки зрения объяснения сигнала, измеренного сенсорами (так как мы
оптимизировали другой функционал качества). Проблема недоопределенности
системы уравнений при этом в некотором смысле остается за скобками, так как для
каждой точки коры решение восстанавливается индивидуально --- без учета вклада
в решение активаций, восстановленных в других точках коры.  Таким образом, для
алгоритмов оптимальной фильтрации найденное решение является
оптимальным в локальном, но не в глобальном смысле.

Задача отыскания активаций, наилучшим образом объясняющих измерения, (т.е.
оптимальных в глобальном смысле) ставится для другого подкласса имиджинговых
методов.
При этом, как уже было отмечено выше, в силу
недоопределенности системы линейных уравнений, связывающих активации на коре с
сигналом на сенсорах, существует бесконечное множество конфигураций источников,
идеально объясняющих померенный сигнал. Тем не менее, среди таких решений в
силу зашумленности измерений а также неточностей при построении прямой модели
реальное распределение активаций (в выделенных точках) коры не содержится, так
как эти <<идеальные>> с точки зрения объяснения измерений решения объясняют в том
числе и шумовую компоненту, которая зачастую оказывается больше или сравнима по
амплитуде с истинной активацией.

Итак, при решении обратной задачи методами глобальной оптимизации существует
две проблемы: бесконечное множество возможных решений и зашумленность
измерений. Чтобы справиться с первой проблемой, для выбора из бесконечного
множества решений пользуются критерием минимальности нормы решения. Иными
словами, среди всех возможных конфигураций первичных токов в объеме (или на
поверхности коры) мозга в качестве решения выбирается такая конфигурация, норма
которой минимальна среди всех возможных.  Условие минимальности нормы в
некотором смысле является следствие принципа бритвы Оккама: мы ищем наиболее
простое решение, удовлетворяющее наблюдениям. Какие решения при этом считать
простыми"--- неочевидный вопрос.  Ответ на него зависит от выбора конкретного
вида нормы, которую мы хотим минимизировать.  Наиболее популярными вариантами
являются $L_2$- и $L_1$-нормы.  Наиболее простой пример минимальной $L_2$-нормы
решения соответствует случаю, когда проблему зашумленности данных мы оставляем
без внимания.  Тогда решение, соответствующее минимуму $L_2$-нормы, получается
применением оператора, соответствующего псевдообратной матрице, взятой для
матрицы прямой модели.  Для $L_1$-нормы ситуация несколько сложнее, так как
решение не может быть получено в явном виде, и требуется численная оптимизация
соответствующего функционала, сводящаяся к задаче линейного программирования.

Рассмотрим теперь, каким образом решается проблема зашумленности данных. Здесь
вновь существует два подхода.  Первый из них используется значительно реже и
состоит в удалении шумовой компоненты из данных посредством сокращенного
сингулярного разложения матрицы прямой модели. Такой подход, например,
использовали авторы, метода Minimum Current Estimate (MCE)~\ref{mce},
порождающего решения с минимальной $L_1$-нормой.

Другой, более популярный подход состоит в использовании тихоновской
регуляризации. В рамках этого подхода норма решения и глобальная ошибка в
объяснении измерений минимизируются совместно, как части одного общего
функционала качества, позволяя тем самым соблюсти баланс между простотой
решения и тем, насколько хорошо оно объясняет измерения, (в том числе,
содержащийся в них шум). Соотношение между <<простотой>> решения и величиной ошибки при
таком подходе можно регулировать настраивая величину метапараметра,
называемого параметром регуляризации. Меняя значение параметра регуляризации
мы стремимся найти такое значение, при котором полученное решение объясняет
только <<полезную>> часть сигнала, записанного сенсорами и полностью игнорирует
шумовую компоненту.

Отметим, что с точки зрения байесовской статистики тихоновская регуляризация
эквивалентна нахождению такого решения обратной задачи, которое соответствует
точке максимума апостериорной плотности вероятности. Минимизируемая норма решения в такой
интерпретации задается априорной плотностью распределения вероятности.

Среди методов, основанных на тихоновской регуляризации, отметим прежде всего
Minimum Norm Estimate (MNE) \ref{mne}, минимизирующий $L_2$-норму решения,
и его вариацию"--- метод dSPM, нормирующий величину восстановленного значения первичного
тока в каждой точке на оцененную величину шума в ней же.

\subsection{Сканирующие алгоритмы} \label{sect_dics}


Наиболее естественным алгоритма поиска фиксированного числа эквивалентных
токовых диполей (dipole fitting), объясняющих данные наилучшим способом,
является оптимизация их положений и ориентаций методом наименьших квадратов.
Такой подход, однако, обладает существенными недостатками, к которым относится
невыпуклость целевой функции при такой оптимизации,
что приводит к застряванию алгоритма в локальных минимумах.

\subsubsection{MUSIC}
Чтобы обойти эту проблему, Мошер и Лихи предложили использовать для
поиска активных токовых диполей алгоритм MUSIC~\ref{MUSIC, Schmidt}, разработанный
и использовавшийся ранее в радиопеленгации и сонарах.

Рассмотрим подробно суть метода в применении к данным ЭЭГ/МЭГ.
Начнем с рассмотрения порождающей модели сигнала на сенсорах, как мы это
уже делали для оценки фазовой синхронности (см.~\ref{gm_ts}).
На этот раз, однако, заложим в модель возможность свободной ориентации диполей.
От каждого активного токового диполя на коре будем иметь вклад на сенсорах вида:

\begin{equation}
    \mathbf{x}_k(t) =
        \begin{bmatrix}
            |                 & |              & |              \\
            \mathbf{g}_k^1    & \mathbf{g}_k^2 & \mathbf{g}_k^3 \\
            |                 & |              & |
        \end{bmatrix}
        \left(\begin{array}{ccc}
                s_{k,1}(t)\\
                s_{k,2}(t)\\
                s_{k,3}(t)
            \end{array}
        \right)
        % \mathbf{s}_{\xi}(t),
\end{equation},
где $k$"--- индекс токового диполя $s_{k,i}$"--- компоненты соответствующего
дипольного момента,
$\mathbf{g}_k^i$"--- вектора-топографии $k$-го токового диполя
для трех ориентаций тока ($i=1,2,3$).
Тогда вклад от всех активных токовых диполей будет виден на сенсорах как

\begin{equation}
    \mathbf{x}(t) = \mathbf{G} \mathbf{s}(t) + \mathbf{\omega}(t),
    \label{gm_music}
\end{equation}

Здесь вновь $\mathbf{s}(t)$ --- $3n$-мерный вектор-столбец активаций источников,
$\mathbf{x}(t)$ --- $m$-мерный вектор-столбец сигналов на сенсорах,
$t$ --- время, а $\mathbf{G}$ --- $m \times 3n$ матрица линейного
отображения пространства источников пространство сенсоров.

Уравнение \ref{gm_music} задает соответствие между пространством источников и пространством
сенсоров для каждого временного среза $t$.
При условии, что было записано $T$ таких срезов,
можем переписать уравнение~\ref{gm_music} в матричной форме:

\begin{equation}
    \mathbf{X} = \mathbf{G} \mathbf{S} + \mathbf{\Omega}
    \label{gm_music_matrix}
\end{equation}

Заметим, что столбцы матрицы $\mathbf{X}$ порождаются линейными комбинациями
векторов-топографий активных токовых диполей, а значит все возможные конфигурации
наблюдаемого сигнала живут внутри некоторого линейного подпространства линейной оболочки этих
топографий. Это линейное подпространство называется \emph{подпространством сигнала}.
При этом количество активных токовых диполей $r$ задает размерность этого подпространства
Чтобы выделить его, применим к матрице $\mathbf{X}$
сингулярное разложение и зафиксируем первые $r$ левых собственных векторов:

\begin{gather}
    \mathbf{U}, \mathbf{S}, \mathbf{V} = svd(\mathbf{X}) \\
    \mathbf{U} =
        \begin{bmatrix}
            |                 &               & |            \\
            \mathbf{u}_1      & \cdots        & \mathbf{u}_m \\
            |                 &               & |
        \end{bmatrix}\\
    \mathbf{U}_r = 
        \begin{bmatrix}
            |                 &               & |            \\
            \mathbf{u}_1      & \cdots        & \mathbf{u}_r \\
            |                 &               & |
        \end{bmatrix}
    % \mathbf{U}_m = U[:,:m]
\end{gather}

Матрица $\mathbf{U}_r$ называется \emph{матрицей подпространства сигнала};
ее столбцы задают ортонормальный базис этого подпространства.
Чтобы найти все активные токовые диполи, для каждого источника на коре
вычислают \emph{корреляцию подпространств} между подпространством сигнала и
линейной оболочкой трех топографий, соответствующих данному источнику.
Корреляция подпространств $C_k$ вычисляется как максимальное собственное число
произведения матрицы левых собственных векторов для топографий $k$-го источника
и матрицы подпространства сигнала:

\begin{gather}
    \mathbf{U}_{k,g}, \mathbf{S}_{k,g}, \mathbf{V}_{k,g} = svd\left(
            \begin{bmatrix}
                |                 & |              & |              \\
                \mathbf{g}_k^1    & \mathbf{g}_k^2 & \mathbf{g}_k^3 \\
                |                 & |              & |
            \end{bmatrix}
     \right)\\
     C_k = \lambda_{max}(\mathbf{U}_{k,g} \mathbf{U}_r^T)
\end{gather}

Активными считаются такие токовые диполи, для которых величина $C_k$ выше некоторого
заранее порога (авторы статьи \ref{MUSIC} рекомендуют для порога значение 0.95).

Таким образом, для нахождения всех активных токовых диполей необходимо
<<просканировать>> объем или поверхность мозга на предмет источников, для которых
корреляция подпространств с подпространством сигнала превышает некоторое
пороговое значение. 

Одним из сущетственных недостатков подхода MUSIC является потенциальная
сложность в разделении нескольких одновременно активных токовых диполей, а также
в выделении ситуации, когда реальный источник имел не фокальную, а распределенную
структуру. В этом случае в распределении в объеме или по поверхности коры
величин $C_k$ будут присутствовать локальные максимумы, анализ которых требует дополнительных
усилий.


\subsubsection{RAP-MUSIC}
Чтобы справиться с этой проблемой, Мошер и Лихи предложили обобщение метода MUSIC, которое
они назвали Recursively applied and projected MUSIC или RAP-MUSIC.

Идея метода заключается в последовательном применении MUSIC-скана для нахождения
диполя с максимальным значением $С$ с последующей проекцией матрицы данных и топографий оставшихся источников
ортогонально подпространству топографий диполя с максимальным $C_k$, с пердыдущей итерации.

Процедура продолжается до тех пор, пока максимальное по источникам значение корреляции подпространств
на новом шаге не опустится ниже порогового значения.

Описание алгоритма RAP-MUSIC на языке псевдокода приведено в листинге \ref{rap_music_listing}.

\begin{ListingEnv}[!h]
    \begin{lstlisting}[language=Python]
def RAP_MUSIC(X, G, threshold):
    """
    Параметры
    ---------
    X : матрица измерений
    G : матрица прямой модели для свободной ориентации
    threshold : порог корреляции подпространств

    Возвращает
    ----------
    active_dipole_indices : индексы найденных диполей

    """
    # инициализируем пустой список индексов активных диполей
    active_dipole_indices = []

    while True:
        # ищем корреляции подпространств для каждого источника
        C = MUSIC_scan(X, G)
        if max(C) < threshold:
            break
        k = argmax(C)
        active_dipole_indices.append(k) 
        # проецируем от диполей k-го источника
        X, G = project_away_from_k(X, G, k) 

    return active_dipole_indices
    \end{lstlisting}
    \label{rap_music_listing}
\end{ListingEnv}

Такая процедура позволяет исключить вклад в измерения от уже найденных
диполей, последовательно объясняя оставшуюся в данных дисперсию.
Пороговый критерий останова алгоритма гарантирует отсутствие ложноположительных
срабатываний.

Отдельного упоминания для алгоритмов MUSIC и RAP-MUSIC заслуживает выбор
ранга подпространства сигнала. С одной стороны, этот ранг должен совпадать
с количеством реально присутствующих в данных диполей. С другой стороны,
a priori, до применения алгоритма это число не известно. Хорошая новость заключается
в том, что переоценка ранга подпространства сигнала практически не влияет на
качество работы этзих двух алгоритмов,
поэтому авторы статей~\ref{MUSIC, RAP_MUSIC} в качестве общей рекомендации
советуют выбирать значения этого ранга больше реально ожидаемых.

Оба алгоритма, будучи достаточно простыми и вычислительно эффективными,
являются удобным инструментом для решения обратной задачи в первом приближении,
что может быть полезно во-первых для примерного понимания картины распределения
источников, а во-вторых в качестве этапа предобработки при решении ОЗ
для сужения количества вариантов поиска с последующим анализом более
изощренными, но не столь вычислительно быстрыми алгоритмами.

\subsection{Алгоритмы пространственной фильтрации}

Другой класс алгоритмов решения обратной задачи основан на методах оптимальной пространственной
фильтрации сигнала. Различные критерии оптимальности порождают при этом различные алгоритмы.
В общем виде задача построения оптимальных пространственных фильтров для $k$-го источника
сводится к нахождению
матрицы $\mathbf{A}_k$, при умножении которой на матрицу данных $\mathbf{X}$, получается
матрица $\mathbf{S}_k$ размером $3\times T$ временных рядов для трех ортогональных
направлений тока в точке $k$, отвечающая некоторому критерию оптимальности:

\begin{equation}
    f(\mathbf{A}_k \mathbf{X}) \rightarrow opt
\end{equation}

Проведем обзор существующих критериев оптимальности и получающихся из них методов на
основании статьи~\ref{Gross_1999}.

\subsubsection{Пространственный фильтр, оптимизирующий отношение сигнал-шум в заданной точке}

Начнем рассмотрение семейства методов пространственной фильтрации с метода, максимизирующего
отношение сигнал-шум в заданной точке.

Сначала определим отношение сигнал-шум в терминах матриц ковариаций шума и данных.
Пусть $\mathbf{R}_{X,k} = \mathbf{X}\mathbf{X}^T$"--- матрица ковариации сигнала на сенсорах,
приходящего от $k$-го источника
(предполагается что мы уже вычли среднее из временных рядов в матрице $\mathbf{X}$),
а $\mathbf{R}_n$"--- матрица ковариации шума на сенсорах. Тогда отношение
сигнал-шум на сенсорах определяеся как

\begin{equation}
    \rho = \frac{tr(\mathbf{R}_{X,k})}{tr(\mathbf{R}_n)}
\end{equation}

Тогда для отфильтрованного  при помощи фильтра $\mathbf{A}_k$
(матрица размером $m \times 3$) $k$-го источника ОСШ будет выглядеть как

\begin{equation}
    \rho_k = \frac{tr(\mathbf{A}_k \mathbf{R}_{X,k} \mathbf{A}_k^T)}{tr(\mathbf{A}_k \mathbf{R}_n \mathbf{A}_k^T)}
\end{equation}

Тогда задача построения пространственного фильтра $\mathbf{A}_k$,
который максимизирует отношение сигнал-шум
для $k$-го отфильтрованного источника формализуется как

\begin{gather}
    \widehat{\mathbf{A}}_k = \underset{\mathbf{A}_k}{argmax}(\rho_k) =
    \underset{\mathbf{A}_k}{argmax}\left(
        \frac{tr(\mathbf{A}_k \mathbf{R}_{X,k} \mathbf{A}_k^T)}
             {tr(\mathbf{A}_k \mathbf{R}_n \mathbf{A}_k^T)}
         \right)\\
    \label{max_snr_objective}
    s.t.: \mathbf{A}_k\mathbf{A}_k^T = \mathbf{I}_3
\end{gather}

Ограничение необходимо, чтобы фильтр не менял пространственную структуру шума.
Шум будем предполагать пространственно белым с дисперсией $\sigma^2_n$
В общем случае это предположение можно удовлетворить
предварительным отбеливанием данных, применив к ним
оператор $\mathbf{R}_n^{-\frac{1}{2}}$.
% Так как к шумовым источникам при восстановлении активности в
% $k$-ой точке коры относится также любая мозговая активность,
% приходящая из других точек коры, на практике построение опператора
% $\mathbf{R}^{-\frac{1}{2}}$ требует априорного знания о распределении
% источников по коре, и следовательно невозможно. Мы можем, однако,
% использовать определенные приближения для матрицы отбеливания.
% Например, в качестве матрицы ковариации шума зачастую используется
% матрица $\mathbf{G}\mathbf{G}^T$, которая действительно являлась
% бы матрицей ковариации шума, если бы в каждой точке коры присутствовал
% единичный шумовой источник.


В одномерном случае, соответствующем фиксированной ориентации диполя,
матрица фильтров $\mathbf{A}_k$ вырождается в вектор-строку,
а матрица ковариации для источника с индексом $k$ приобретает вид

\begin{equation}
    \mathbf{R}_{X,k} = \sigma^2 \mathbf{g}_k \mathbf{g}_k^T
\end{equation}

где $\sigma^2_k$ --- дисперсия сигнала.
Для матрицы ковариации шума в предположении, что он является пространственно белым, 
будем иметь $\mathbf{R}_n = \mathbf{I}$.
Тогда~\ref{max_snr_objective} в одномерном случае преобразуется к виду

\begin{equation}
    \widehat{\mathbf{A}}_k =
        \underset{\norm{\mathbf{A}_k} = 1}{argmax}\left(
            \frac{\sigma_k^2\norm{\mathbf{A}_k \mathbf{g}_k}^2}
                 {\sigma_n^2\mathbf{A}_k \mathbf{I} \mathbf{A}_k^T}
             \right) = \frac{\sigma_k^2}{\sigma_n^2}\underset{\norm{\mathbf{A}_k} = 1}{argmax}\left(
                \norm{\mathbf{A}_k \mathbf{g}_k}^2
             \right)
\end{equation}


Очевидно, что среди всех векторов единичной длины максимальное значение ОСШ
будет достигаться на векторе, сонаправленном с ориентацией вектора топографии $\mathbf{g}_k$:

\begin{equation}
    \widehat{\mathbf{A}}_k = \frac{\mathbf{g}_k^T}{\norm{\mathbf{g}_k}}
\end{equation}

В случае свободной ориентации диполя матрица $\mathbf{R}_{X,k}$ примет вид

\begin{equation}
    \mathbf{R}_{X,k} = \sigma_k^2 \left[ \mathbf{g}_k^1, \mathbf{g}_k^2, \mathbf{g}_k^3 \right] \left[\mathbf{g}_k^1, \mathbf{g}_k^2, \mathbf{g}_k^3\right]^T
\end{equation}

В этом случае любые три вектора (два в случае МЭГ),
образующие ортонормированный базис подпространства, натянутого на
вектора $\mathbf{g}_k^1, \mathbf{g}_k^2, \mathbf{g}_k^3$,
могут быть использованы как компоненты оптимального фильтра.
В частности, для построения фильтра $\mathbf{A}_k$ можем использовать
первые три левых сингулярных вектора матрицы $\mathbf{g}_k$:

\begin{gather}
    \mathbf{U}_{k,g}, \mathbf{S}_{k,g}, \mathbf{V}_{k,g} = svd\left(
            \begin{bmatrix}
                |                 & |              & |              \\
                \mathbf{g}_k^1    & \mathbf{g}_k^2 & \mathbf{g}_k^3 \\
                |                 & |              & |
            \end{bmatrix}
     \right)\\
    \widehat{\mathbf{A}}_k = 
            \begin{bmatrix}
                |                 & |              & |              \\
                \mathbf{U}_{k, g}^1    & \mathbf{U}_{k,g}^2 & \mathbf{U}_{k,g}^3 \\
                |                 & |              & |
            \end{bmatrix}
\end{gather}

Действительно, проекция векторов фильтра
на ортогональное дополнение линейной оболочки векторов
$\mathbf{g}_k^1, \mathbf{g}_k^2, \mathbf{g}_k^3$,
при подсчете произведения $\mathbf{A}_k \mathbf{g}_k \mathbf{g}_k^T \mathbf{A}_k^T$
будет давать нулевой вклад, а значит, так как вектора $\mathbf{A}_k$
фиксированной длины (единичные), они должны целиком принадлежать
линейной оболочке $span(\mathbf{g}_k^1, \mathbf{g}_k^2, \mathbf{g}_k^3)$.
Вместе с тем, из ограничения $\mathbf{A}_k \mathbf{A}_k^T = \mathbf{I}_3$ следует, что
матрица $\mathbf{A}_k$ является матрицей перехода от одного ортонормированного базиса
линейной оболочки $span(\mathbf{g}_k^1, \mathbf{g}_k^2, \mathbf{g}_k^3)$ к другому,
а произведение $\mathbf{A}_k \mathbf{g}_k \mathbf{g}_k^T \mathbf{A}_k^T$
реализует этот переход.
Но след матрицы является инвариантом при переходе от одного ортонормированного базиса к другому,
а значит $tr(\mathbf{A}_k \mathbf{g}_k \mathbf{g}_k^T \mathbf{A}_k^T)$
будет одинаков для любого $\mathbf{A}_k$, строки которого образуют ортонормированный базис
$span(\mathbf{g}_k^1, \mathbf{g}_k^2, \mathbf{g}_k^3)$.

% Установим теперь связь фильтрации, максимизирующей ОСШ, с алгоритмом MUSIC.
Рассмотрим теперь способ получения фильтра, оценивающего истинную ориентацию диполя
и восстанавливающего сигнал вдоль этой ориентации.
После применения полученной матрицы фильтра $\mathbf{A}_k$ к данным,
мы будем получать три временных ряда, соответствующих трем ортогональным направлениям
тока в точке $k$. Для получения фильтра, восстанавливающего единственный временной ряд
вдоль истинной ориентации тока в $k$-ой точке также пользуются критерием максимизации ОСШ.
В этом случае ставится задача отыскания такой ориентации фильтров
$\mathbf{\theta}_k = (\theta^1, \theta^2, \theta^3)^T$, для
которой отфильтрованный сигнал $\mathbf{S}_k = \mathbf{\theta}_k^T \hat{\mathbf{A}}_k \mathbf{X}$
будет обладать максимальной мощностью среди всех возможных ориентаций.

Для нахождения такой ориентации достаточно взять собственный вектор матрицы
$\hat{\mathbf{A}}_k \mathbf{X}\mathbf{X}^T \hat{\mathbf{A}}_k^T$,
соответствующий ее максимальному собственному числу.
Тогда ориентированный фильтр будет выглядеть как

\begin{equation}
    \hat{\mathbf{A}}_{or k} = \mathbf{\theta}^T \hat{\mathbf{A}}_k
\end{equation}

Заметим, что процедура построения такого фильтра очень похожа на способ
вычисления корреляции подпространств в алгоритме MUSIC.
% Полученный вектор в силу свойств сингулярного разложения
% будет иметь максимальную проекцию на подпространство, натянутое на столбцы
% матрицы $\mathbf{X}$, a значит, так как его длина фиксирована и равна единице,
% этот вектор будет составлять минимальный угол с линейной оболочкой
% столбцов $\mathbf{X}$.

\subsubsection{Пространственный фильтр, минимизирующий вклад третих источников в оценку}

Рассмотрим теперь пространственный фильтр,
оптимизационным критерием которого является задача минимизации
вклада активных источников, находящихся в отличных от целевой точках коры.
Этот критерий эквивалентен задаче отыскания фильтра, для котрого отфильтрованный
сигнал будет обладать минимальной энергией при условии, что
сигнал из целевой точки фильтром не искажается.

Математически эта задача в случае фиксированной ориентации диполей запишется как

\begin{equation}
    \hat{\mathbf{A}}_k = \underset{\mathbf{A}_k}{argmin} (\Expect{\norm{\mathbf{A}_k \mathbf{X}}^2}),
    s.t.: \mathbf{A}_k \mathbf{g}_k = 1
\end{equation}

Выпишем соответствующий лагранжиан c учетом того, что $\mathbf{R}_{\mathbf{X}} = \Expect{\mathbf{X}\mathbf{X}^T}$
~---это матрица ковариации сигнала на сенсорах:

\begin{equation}
    f_L(A, \lambda) = \mathbf{A}_k \mathbf{R}_{\mathbf{X}} \mathbf{A}_k^T + \lambda (\mathbf{A}_k \mathbf{g}_k - 1)
\end{equation}


Далее, приравняв производную лагранжиана по $\mathbf{A}_k ^ T$ к нулю, будем иметь:

\begin{equation}
    \frac{\partial f_L}{\partial \mathbf{A}_k} = 
    2 \mathbf{R}_{\mathbf{X}} \mathbf{A}_k^T + \lambda \mathbf{g}_k = 0
\end{equation}

Откуда

\begin{equation}
    \mathbf{A}_k = - \frac{\lambda}{2} \mathbf{g}_k^T\mathbf{R}_{\mathbf{X}}^{-1}
\end{equation}

Используя ограничение, получим

\begin{equation}
    1 = \mathbf{A}_k \mathbf{g}_k =
    - \frac{\lambda}{2} \mathbf{g}_k^T\mathbf{R}_{\mathbf{X}}^{-1} \mathbf{g}_k \implies
    \lambda = -\frac{2}{\mathbf{g}_k^T \mathbf{R}_{\mathbf{X}}^{-1} \mathbf{g}_k}
\end{equation}

Окончательно, будем иметь

\begin{equation}
    \hat{\mathbf{A}}_k =
    \frac{\mathbf{g}_k^T \mathbf{R}_{\mathbf{X}}^{-1}}{\mathbf{g}_k^T \mathbf{R}_{\mathbf{X}}^{-1} \mathbf{g}_k}
\end{equation}
