\chapter{Структура порождающей модели матрицы кросс-спектральной плотности.
         Подпространство протечки сигнала.} \label{chapt1}

\section{Введение}
% План вводной части основного текста:
% Из чего мозг состоит и то, что электрические сигналы -- один из основных
% способов передачи инвормации между нейронами.
% В силу иерархичности системы информация передается не только от нейрона к нейрону,
% но и от популяции к популяциии. Ритмы мозга --- очень кратко.

% Есть гипотеза, что моменты коммуникации между популяциями сопровождаются когерентной
% активностью популяций. Есть и более сложные механизмы, нелинейной синхронизации,
% но они за пределами этого диссера.
% Что такой когерентность двух абстрактных сигналов (не про мозг).
% Зависимость от фазового угла мнимой и действительной части комплексной когерентности.
% Корреляция огибающей, коэффициент фазовой связности, Когерентность vs PLV для циркулярно-гауссовых сигналов.

% ЭЭГ и МЭГ как неинвазивный метод измерения электрической активности мозга.
% Пирамидальные клетки, их апикальные дендриты,
% пресинаптические\постсинаптические потенциалы, локальная синхронизация,
% токовый диполь, уравнения максвелла и их решение для диполя, топография
% и временная последовательность активации диполя, пару слов вращающемся диполе --
% просто как о модели, описывающей периодическое смещение активности,
% модель всего мозга, сетка объемная, сетка на коре, матрица прямой модели,
% топографии диполей как столбцы матрицы прямой модели и строки как поля
% чувствительности (lead fields), шум мозга и моделирование шума мозга. Модель ЭЭГ и МЭГ измерений
% X = GS + bn + b

Чтобы обрисовать контекст, в котором задача оценки коннективностей имеет смысл,
необходимо сперва описать основные принципы работы мозга, механизмы передачи
информации между нейронными популяциями и то, каким образом мы можем получить
информацию о таком обмене информацией средствами неинвазивной электрофизиологии.

Согласно оценкам \ref{gorine}, в мозге здорового взрослого человека присутствует
порядка 83 миллиардов нейронов. Каждый отдельно взятый нейрон представляет собой
сравнительно простой биохимический механизм, принимающий электрические импульсы
от других нейронов на вход и способный генерировать выходной импульс в случае,
если входной сигнал превышает определенный порог. Тем не менее, этого элементарного
функционала отдельно взятых нейронов оказывается достаточно для обеспечения сложнейшей работы
головного мозга в целом.

Мозг, таким образом, представляет собой сложную систему, составленную из сравнительно
просто устроенных элементов.
Для науки по-прежнему остается загадкой, за счет чего достигается
качественный скачок в поведении системы, состоящей из совокупности
нервных клеток, на пути от простой биоэлектрической сети,
узлы которой способны обмениваться электрическими импульсами, к
системе, обладающей интеллектом и сознанием собственного ``я''.
Каким-то образом оказывается возможен переход количества в качество, --- увеличение
числа сравнительно простых элементов системы,
таких как нейрон, до невероятных 83 миллиардов порождает удивительную
сложность и богатство поведенческих сценариев.

Тем не менее есть надежда, что ключ к пониманию работы мозга по крайней мере
частично лежит в изучении работы отдельных его частей и
способов обмена информацией между ними.

Разберем сперва, какие именно механизмы позволяют нейронам обмениваться
электрическим сигналом на примере пирамидальных нейронов, из которых по
большей части и состоит кора больших полушарий.

Пирамидальный нейрон, как и любой другой, имеет аксон и
разветвленную сеть отростков, называемых дендритами.
Активность нейрона характеризуется генерацией так называемых
потенциалов действия или спайков в ответ на внешний электрохимический вход.

Потенциалы действия, распространяясь по аксону, достигают синаптической
щели. Пришедший импульс играет роль триггера, провоцируя выделение
нейромедиаторов в  синаптическую щель. Нейромедиаторы достигают окончания
дендрита следующего нейрона, вызывая в нем увеличение, либо ослабление
трансмембранного потенциала --- в зависимости от того, являлся ли
нейрон, сгенерировавший потенциал действия, тормозным или возбуждающим.
Трансмембранный потенциал определяется как разность потенциалов между
внешней и внутренней поверхностью мембраны клетки и зависит от молярных
концентраций ионов по обе стороны мембраны.
В такой схеме обмена информацей между двумя нейронами первый нейрон,
породивший потенциал действия, называется пресинаптическим, а второй,
принимающий сигнал --- постсинаптическим.

При этом, к каждому нейрону подведено множество аксонов.
Трансмембранный потенциал отдельно взятого нейрона
аккумулирует воздействия от нейронов, с которыми у него
имеются синаптические связи. Будучи равным $\approx -70$ микровольт
в покое, трансмембранный потенциал изменяется в результате
потенциалов действия, приходящих от пресинаптических нейронов и,
в при достижении порога деполяризации мембраны в $\approx -30$ микровольт
постсинаптический нейрон сам производит потенциал действия.
Таким образом,
нейроны выполняют роль сумматоров в иерархической сети передачи сигнала.

Однако, прежде чем трансмембранный потенциал клетки ``почувствует''
изменения, пришедший импульс должен через дендритные отростки достичь мембраны.
Электрический потенциал, распространяющийся по дендриту от синапса к мембране
носит название постсинаптического потенциала. При этом, само распространение
электрической активности по дендриту есть ни что иное как движение ионов, то есть
электрический ток. На макроуровне совокупность нейронов и окружающая их спинномозговая
жидкость представляют собой объемный проводник, из-за чего распространение токов
вдоль дендритных отростков, называемых \emph{первичными токами},
вызывает появление \emph{вторичных} объемных токов в мозге.

Вследствие такой электрохимической проницаемости трансмембранные потенциалы локальных
нейронных популяций оказываются связаны между собой. В силу того, что именно
трансмембранный потенциал управляет генерацией потенциала действия, а значит и
передачей информации от нейрона к нейрону, оказывается, что отдельные нейроны
в информационном смысле не изолированы друг от друга,
и можно говорить о передаче информации не только от нейрона к нейрону,
но и от популяции нейронов к популяции.

Ключевой особенностью для работы групп пирамидальных нейронов является особая организация их
дендритных отростков, а именно --- наличие одного выделенного дендрита,
значительно превосходящего по размерам остальные. Такой дендрит
называется апикальным, а все остальные в рамках такой дихотомии --- базальными.

Пространственно апикальные дендриты пирамидальных нейронов в коре больших полушарий организованы
весьма особым образом --- если говорить о локальной популяции,
апикальные дендриты в ней ориентированы параллельно друг другу. Вследствие этого первичные
токи пирамидальных нейронов внутри популяции суммируются, делая возможным их детектирование
в неинвазивной электрофизиологии. Действительно, электрическая активность отдельного
нейрона слишком слаба для регистрации за пределами черепной коробки существующими сегодня методами,
в то время как  суммарная активность групп из десятков тысяч нейронов
в силу коллинеарности их апикальных дендритов производит достаточный ток для регистрации
за пределами головы.
% TODO: какой ток? посмотри хамалайнена <22-01-18, yourname> %



Таким образом, обмен информацией между нейронами происходит посредством двух основных механизмов~---
за счет распространения по аксону потенциала действия и за счет распространения постсинаптических
потенциалов, при чем оба эти механизма тесно связаны между собой.

Одним из эпифеноменов такой взаимосвязи является появление в паттернах суммарного постсинаптического
потенциала ритмической осцилляторной активности на сравнительно низких частотах.
Широко известен, например, альфа-ритм, традиционно относимый к полосе частот $8-12$ Гц,
с регистрации которого в 1924 году немецким физиологом Гансом Бергером ведет отсчет
современная электрофизиология.

Стоит отметить, что выделение отдельных полос частот из общего спектра электрической активности
групп нейронов неслучайно и связано с определенными функциональными атрибутами, различными
физиологически обусловленными причинами их возникновения а также с их пространственной специфичностью.
Так, уже упомянутый альфа-ритм в покое наиболее сильно представлен в затылочных долях мозга
и считается ритмом покоя зрительной коры в отсутствие визуального раздражения.
К другим функционально-специфичным и широко освещенным в литературе полосам частот
относят дельта-, тета-, бета- и гамма-ритмы.


Роль осцилляций в передаче информации между нейронными ансамблями на сегодняшний день
все еще остается плохо изученной, однако согласно доминирующей в научном сообществе
гипотезе взаимодействия через когерентность \ref{fries}, именно осцилляции постсинаптического
потенциала являются медиатором коммуникации между отдельными областями коры.

Такое взаимодействие предполагается необходимым в осуществлении так называемой
\emph{функциональной интеграции}. Суть понятия функциональной интеграции состоит в следующем.

Известно, что существуют определенные зоны мозга, активность в которых функционально специфична.
Так, например, было показано, что электрическая стимуляция определенных областей
прецентральной зоны провоцирует неконтролируемые движения а иногда и активирует целые двигательные программы.
При этом в зависимости от конкретного места стимуляции задействуются различные части тела.
Эти области прецентральной зоны принято называть первичной моторной корой.
Оказыватся, что в первичной моторной коре представлена подробная карта тела человека.
Аналогичная ситуация наблюдается и для постцентральной зоны --- стимуляция соответствующих
областей вызывает тактильные ощущения в различных частях тела. Источник тактильного ощущения
на теле при этом также зависит от конкретного места стимуляции. В соответствии с этим выделяют
соматосенсорную кору. Такие функционально-специфичные зоны коры существуют и для других отделов
мозга. Тем не менее, не всякую активность удается так хорошо локализовать на коре.

Так или иначе, субъективные ощущения подсказывают нам, что в реальной жизни деятельность мозга никогда
не сводится к какой-либо одной отдельно взятой функции, как, скажем, движение указательным пальцем.
Скорее наоборот, большое количество параллельных, но связанных друг с другом процессов
осуществляется мозгом одновременно. При этом для нормальной работы такие процессы должны
взаимодействовать друг с другом.
Для примера возьмем задачу в которой испытуемому предлагали зажечь спичку, а затем проделать то же самое,
но с предварительной анастезией кончиков пальцев. Было показано, что потеря чувствительности
ведет к весьма значительному увеличению времени на выполнение той же задачи.
Из этого можно заключить, что информация о тактильных ощущениях определенным образом
\emph{интегрируется} мозгом с двигательной программой при выполнении задачи зажигания спички.

Термин \emph{функциональная интеграция} используется для обозначения такого явления взаимодействия
функционально-специфичных отделов мозга для решения сложной когнитивной задачи, как в задаче со спичкой.
Предполагается, что раз существуют зоны мозга, ответственные за осуществление той или иной функции,
и активные во время осуществления этой функции, то совместное осуществление нескольких таких функций,
требующих обмена информацией между собой должно вызывать совместную активацию соответствующих областей
мозга и обмен информацией между ними.

Теперь, введя понятие функциональной интеграции, мы можем вернуться к гипотезе \emph{взаимодействия
через когерентность}. Согласно этой гипотезе, функциональная интеграция реализуется в мозге посредством
установления когерентных осцилляций постсинаптических потенциалов во взаимодействующих областях коры.

% TODO: find paper on motor cortex and stimulation  <22-01-18, yourname> %
% TODO: find paper by sliman with dumb finger tips  <22-01-18, yourname> %

Обоснование гипотезы состоит в следующем.
Вероятность того, что нейрон произведет потенциал действия тем больше, чем выше
величина локального постсинаптического потенциала. В силу того, что этот потенциал осциллирует,
нейрон способен реагировать на входящие потенциалы действия не всегда, а только в те моменты,
когда он был уже достаточно возбужден, т.е. тогда, когда локальный постсинаптический потенциал
находился в максимуме. Рассмотрим теперь два нейрона, находящиеся в двух различных нейронных
популяциях. Назовем первый из них нейроном A, а второй --- нейроном B.
Для успешной передачи информации от нейрона A к нейрону B
необходимо, чтобы потенциал популяции нейрона B имел достаточно высокое значение в тот момент,
когда спайк от нейрона A достигнет цели. Кроме того, чтобы нейрон A был способен произвести
спайк, локальный потенциал его популяции в момент генерации также должен быть достаточно высок.
Иными словами, осцилляции постсинаптического потенциала регулируют моменты возможного
приема и передачи информации между нейроном A и нейроном B. Таким образом, возникает два
временных окна, ритмически появляющихся и пропадающих во времени --- первое окно
соответствует промежуткам времени, когда нейрон A может передать сигнал, а второе --- тем
моментам времени, когда нейрон B может его принять.
Если считать, что потенциал действия распространяется от аксона нейрона A к дендриту нейрона B
каждый раз за одно и то же время, то для установления стабильного канала передачи информации от
нейрона A к нейрону B необходимо, чтобы эти два окна открывались и закрывались через
одинаковые промежутки времени, и чтобы окна приема информации было сдвинуто относительно
окна передачи на величину, равную времени распространения сигнала от нейрона A к нейрону B.
Последнее справедливо в том случае, если осцилляции двух нейронных популяций \emph{когерентны},
то есть имеют одинаковую частоту и, возможно, некоторый ненулевой фазовый сдвиг.
Таким обзазом, согласно гипотезе взаимодействия через когерентность, синхронизация осцилляций
нейронных популяций способствует обмену информацией в виде потенциалов действия между ними,
в то время как рассинхронизация осцилляций ведет к блокированию обмена сигналами.


\subsubsection{Формальное определение когерентности}
Дадим более формальное определение когерентности абстрактных сигналов.
Пусть имеется два случайных процесса $s_1, s_2$:
\begin{equation}
    s_1 = s_1(t,\omega), s_2 = s_2(t,\omega)
\end{equation}
где переменная $t$~--- время, а $\omega$~--- случайная величина из вероятностного пространства $\Omega$.
Под сигналами $s_1(t), s_2(t)$ будем понимать конкретные реализации случайных процессов
$s_1(t,\omega), s_2(t,\omega)$, фиксируя величину $\omega = \omega_0$.

Наиболее естественным способом проверить,
является ли один случайный процесс сдвинутой во времени копией другого,
является подсчет кросс-ковариации, которая определяется как:

\begin{equation}
    C_{s_1, s_2}(t_1,t_2) = cov(s_1(t_1), s_2(t_2)) \defeq
    \Expect{(s_1(t_1,\omega) - \mu_1(t_1))(s_2(t_2,\omega) - \mu_2(t_2))}
\end{equation}
где $\mu_i(t_i) = E(s_i(t_i)), i=1,2$~--- среднее по ансамблю функции случайной величины величины
$s_i(t_i,\omega)$.
Для простоты изложения будем считать, что сигналы имеют нулевое среднее, имея в виду,
что мы всегда можем вычесть
среднее по ансамблю из каждой реализации случайного процесса.
Рассмотрим сначала случай стационарных в широком смысле процессов,
а потом обобщим рассуждения на случай нестационарности.
Стационарными в широком смысле называются такие случайные процессы,
для которых среднее не зависит от времени, а автоковариация зависит только от сдвигов по времени.
Кроме того, мы потребуем от процессов \emph{совместной} стационарности в широком смысле,
то есть мы будем считать, что кросс-ковариация, также зависит только от сдвига по времени $\tau = t_2 - t_1$:

\begin{equation}
    C_{s_1,s_2}(t_1,t_1+\tau) = C_{s_1,s_2}(\tau)
\end{equation}

Введем дополнительные понятия, которые понадобятся нам для определения когерентности.
Сперва вспомним понятие энергии сигнала.
Энергией сигнала на промежутке~$\Big[{-\frac{T}{2}},\frac{T}{2}\Big]$ называют величину
\begin{equation}
    E_T \defeq \Expect{\int\limits_{-T/2}^{+T/2} \abs{s(t,\omega)} ^ 2 dt}
\end{equation}

Полная энергия сигнала получается взятием предела от $E_T$:

\begin{equation}
    E \defeq \lim_{T \to \infty} E_T
\end{equation}

Для стационарных процессов, однако, величина полной энергии, вообще говоря, не определена,
поэтому вводят понятие средней мощности сигнала:

\begin{equation}
    P \defeq \lim_{T \to \infty}\frac{E_T}{T}
\end{equation}

Введем операцию преобразования Фурье на отрезке $\Big[{-\frac{T}{2}},\frac{T}{2}\Big]$
для процесса~$s$ следующим образом:

\begin{equation}
    F_s^T(f,\omega) \defeq \frac{1}{\sqrt{T}}\int\limits_{-T/2}^{T/2} s(t,\omega) e^{-ift} dt
\end{equation}

Тогда, пользуясь теоремой Парсеваля, для средней мощности сигнала будем иметь
\begin{equation}
    P = \lim_{T \to \infty} \Expect{\int\limits_{-\infty}^{+\infty}\abs{F_s^T(f,\omega)}^2df}
\end{equation}

Далее, определим спектральную плотность мощности сигнала:

\begin{equation}
    S_{ss}(f) \defeq \lim_{T \to \infty} \Expect{\abs{F_s^T(f,\omega)} ^ 2}
    \label{psd_def}
\end{equation}

Спектральная плотность мощности характеризует распределение мощности сигнала по частотам.
По аналогии с \ref{psd_def} вводят понятие кросс-спектральной плотности мощности

\begin{equation}
    S_{s_1,s_2}(f) \defeq \lim_{T \to \infty} \Expect{\conj{F_{s_1}^T(f,\omega)} F_{s_2}^T(f,\omega)}
    \label{csp_def}
\end{equation}

Введя основные понятия, мы готовы теперь определить когеренцию и дать интуитивное представление о том,
почему величина когерентности отражает степень синхронизации сигналов.

Для частотного образа функции кросс-ковариации случайных процессов, стационарных в широком смысле, справедлива
теорема Винера-Хинчина, согласно которой кросс-ковариация и кросс-спектральная плотность мощности
связаны друг с другом через преобразование Фурье:

\begin{equation}
    S_{s_1, s_2}(f) = \int\limits_{-\infty}^{+\infty}C_{s_1,s_2}(\tau)e^{-if\tau}d\tau
\end{equation}

Или, используя \ref{csp_def}:

\begin{equation}
    \lim_{T \to \infty} \Expect{\conj{F_{s_1}^T(f,\omega)} F_{s_2}^T(f,\omega)} =
    \int\limits_{-\infty}^{+\infty}C_{s_1,s_2}(\tau)e^{-if\tau}d\tau
\end{equation}

Рассмотрим подробнее, как устроено произведение
$\conj{F_{s_1}^T(f,\omega)} F_{s_2}^T(f,\omega)$.
Пользуясь экспоненциальным представлением комплексного числа, для коэффициента Фурье на частоте $f$
будем иметь:

\begin{equation}
    F_{s_j}^T(f) = A_j(f) * e^{i\phi_j}, j=\overline{1,2}
    \label{exp_fourier}
\end{equation}

где $A_i(f)$~--- амплитуда синусоиды на частоте $f$ в соответствующем разложении Фурье, а
$\phi_i$~--- ее фаза.
Отметим, что частотное представление позволяет в явном виде получить доступ к фазе сигнала.

Используя \ref{exp_fourier}, можем переписать выражение для произведение фурье-образов
на отрезке $\Big[{-\frac{T}{2}}, \frac{T}{2}\Big]$ как:
\begin{equation}
    \conj{F_{s_1}^T(f,\omega)} F_{s_2}^T(f,\omega) =
    A_1(f,\omega)A_2(f,\omega) e^{i(\phi_2(f,\omega) - \phi_1(f,\omega))}
\end{equation}

Из соотношения выше видно, что на частоте $f$ фаза произведения фурье-образов
реализаций случайного процесса совпадает с разностью фаз соответствующих
комплексных экспонент для индивидуальных преобразований Фурье. Применяя далее
операцию усреднения по ансамблю, получим значение кросс-спектральной плотности мощности
на частоте $f$:

\begin{equation}
    S_{s_1, s_2}(f) = \Expect{A_1(f,\omega)A_2(f,\omega) e^{i(\phi_2(f,\omega) - \phi_1(f,\omega))}}
    \label{csp_exp}
\end{equation}

Таким образом, мы получили, что значение кросс-спектральной плотности мощности равно
среднему по ансамблю от комплексного числа, аргумент которого равен разности фаз
гармоник индивидуальных сигналов с частотой $f$, а  модуль~--- произведению амплитуд этих гармоник.
Имея в виду, что поле комплексных чисел изоморфно двумерному векторному пространству, можем понимать
операцию усреднения в уравнении \ref{csp_exp} как усреднение векторов на плоскости,
повернутых относительно направления оси абсцисс на угол, равный разности фаз сигналов.
Нетрудно понять, что средний вектор при фиксированных амплитудах будет иметь тем большую норму,
чем более воспроизводима соответствующая разность фаз по реализациям случайного процесса.
Воспроизводимая по реализациям разность фаз, в свою очередь, свидетельствует
о синхронизации случайных процессов, т.е. о наличии некой линейной связи между ними.
Таким образом, длина результирующего вектора может служить мерой синхронности случайных процессов.
Вместе с тем, чтобы исключить влияние амплитуды на получающееся значение, применяют нормировку на
среднее по ансамблю значение мощностей сигналов на той же частоте.
Получающаяся нормированная величина и есть по определению когерентность двух сигналов:

\begin{equation}
    G_{s_1,s_2}(f) \defeq \frac{S_{s_1,s_2}(f)}{\sqrt{S_{s_1,s_1}(f)S_{s_2,s_2}(f)}}
    \label{def_coh}
\end{equation}

Или, используя определение кросс-спектральной плотности мощности:

\begin{equation}
    G_{s_1,s_2}(f) = \lim_{T \to \infty}
    \frac{\Expect{\conj{F_{s_1}^T(f)}F_{s_2}^T(f)}}
    {\sqrt{\Expect{\conj{F_{s_1}^T(f)}F_{s_1}^T(f)}
    \Expect{\conj{F_{s_2}^T(f)}F_{s_2}^T(f)}}}
\end{equation}

Определенная таким образом функция когерентности может быть использована
лишь для стационарных в широком смысле сигналов.
В то же время предположение о стационарности зачастую противоречит природе изучаемых
процессов. В частности, нестационарны по своей природе сигналы, возникающие в
электрофизиологии.
Тем не менее, возможно обобщить определение когерентности и на случай нестационарности.
Обобщение достигается путем использования вместо преобразования Фурье одного из
\emph{частотно-временных преобразований}.
В частности, можно использовать преобразование Фурье с окном, вейвлет-преобразование или узкополосную
фильтрацию с центральной частотой $f$ с последующим извлечением аналитического сигнала.

В каждом из этих методов возникает характерная ширина
временного окна (возможно различная для разных частот $f$).
Предполагая, что статистические свойства случайного процесса меняются со временем медленно,
можем повторить рассуждения выше для сужения стационарных процессов
на временное окно частотно-временного преобразования за исключением перехода,
для которого мы использовали теорему Винера-Хинчина.
Теорема Винера-Хинчина, однако, также допускает обобщение на случай нестационарных процессов \ref{Paper2009}.

Таким образом, для нестационарных процессов будем иметь:

\begin{equation}
    G_{s_1,s_2}(f,t) \defeq
    \frac{\Expect{\conj{\mathcal{F}_{s_1}(f,t,\omega)}\mathcal{F}_{s_2}(f,t,\omega)}}
    {\sqrt{\Expect{\conj{\mathcal{F}_{s_1}(f,t,\omega)}\mathcal{F}_{s_1}(f,t,\omega)}
    \Expect{\conj{\mathcal{F}_{s_2}(f,t,\omega)}\mathcal{F}_{s_2}(f,t,\omega)}}}
    \label{nonwss_coh_def}
\end{equation}
где $\mathcal{F}_{s_i}(f,t,\omega)$~--- частотно-временной образ сигнала $s_i$ ($i=\overline{1,2}$)

Отметим одно интересное свойство функции когерентности.
Как в стационарном, так и в нестационарном случае когерентность является комплекснозначной функцией
частоты $f$. При этом значения этой функции, согласно \ref{csp_exp}, пропорциональны
средневзвешенной комплексной экспоненте с аргументом, зависящим от разности фаз.
При этом веса равны произведениям амплитуд исходных сигналов на заданной частоте.
Если в иллюстративных целях, что амплитуды и фазы независимы, получим для когерентности следующее выражение:

\begin{equation}
    G_{s_1,s_2}(f,t) =
    \frac{\Expect{A_1(f,t,\omega)A_2(f,t,\omega)}}
    {\sqrt{\Expect{A_1(f,t,\omega)^2}\Expect{A_2(f,t,\omega)^2}}}\Expect{e^{i\Delta\phi(f,t,\omega)}},
\end{equation}
где $\Delta\phi = \phi_2 - \phi_1$. Рассмотрим подробнее множитель $\Expect{e^{i\Delta\phi(f,t,\omega)}}$.
В случае, если разность фаз $\Delta\phi$ от реализации к реализации будет иметь воспроизводимые близкие к нулю значения,
средняя комплексная экспонента также будет иметь близкий к нулю аргумент, т.е. действительная часть результирующей
комплексной экспоненты будет иметь высокое значение по сравнению с мнимой частью.
Иными словами, если случайные процессы были синхронизированы с нулевой фазой, их функция когерентности
будет иметь почти действительные значения. С другой стороны, если разность фаз воспроизводимо близка к $\pi/2$,
итоговое значение когерентности будет близко к мнимому числу.
Это наблюдение понадобится нам в дальнейшем, так как одной из наиболее популярных сегодня методик оценки
коннективности на неинвазивных данных является так называемая мнимая часть когерентности.

% PLV vs coh {{{plv %
% Тем не менее, предположение о независимости амплитуд и фаз сигналов вообще говоря неверно.
% Кроме того, амплитуды двух сигналов могут быть также коррелированы, что приводит к определенным
% затруднениям при интерпретации результатов анализа, полученных на основе рассчета когерентности.

% Чтобы исключить влияние амплитуд на оценку фазовой связности случайных процессов,
% была предложена мера, получившая название ``коэффициент фазовой связности'' (phase locking value, PLV) \ref{PLV},
% которая определяется как

% \begin{equation}
%     PLV_{s_1,s_2}(f,t) \defeq \abs{\Expect{e^{i\Delta\phi(f,t,\omega)}}}
% \end{equation}

% Или, через образы частотно-временных преобразований:

% \begin{equation}
%     PLV_{s_1,s_2}(f,t) = \Expect{\frac{\conj{\mathcal{F}_{s_1}(f,t,\omega)}\mathcal{F}_{s_2}(f,t,\omega)}
%     {\abs{\mathcal{F}_{s_1}(f,t,\omega)}\abs{\mathcal{F}_{s_2}(f,t,\omega)}}}
% \end{equation}
% plv}}} %

\subsubsection{Модель неинвазивных измерений при помощи МЭГ/ЭЭГ}
В предыдущих разделах мы рассмотрели, каким образом установление когерентных
осцилляций между постсинаптическими потенциалами нейронных популяций позволяет
осуществлять функциональную интеграцию, а также сделали первый шаг на пути к оценке когерентности
на основании измерений электрической активности мозга~--- дали формальное определение функции когерентности
двух случайных процессов.

В определении когерентности \ref{def_coh} фактически содержится рецепт ее вычисления --- нам лишь
необходимо оценить значения соответствующих мат. ожиданий из данных.

Однако в неинвазивной электрофизиологии мы не имеем прямого доступа к локальным осцилляциям потенциалов
в нейронных популяциях, так как активность мозга регистрируется при помощи сенсоров, находящихся за пределами
головы и следовательно отражает некую суммарную активацию нейронных ансамблей.

Как было отмечено выше, источником сигнала, снимаемого при помощи ЭЭГ или МЭГ служат
первичные токи, т.е. токи, распространяющиеся вдоль апикальных дендритов пирамидальных нейронов коры.
Первичные токи вызывают появление вторичных токов в объемном проводнике, коим является мозг.
В силу параллельной ориентации апикальных дендритов, электромагнитные поля, порождаемые
первичными токами, накладываются, генерируя суммарное электрическое поле достаточной силы для
регистрации за пределами головы.

Чтобы понять, как соотносятся суммарные колебания постсинаптического потенциала,
порождаемые нейронными популяциями, с регистрируемым сигналом,
начнем с рассмотрения уравнений Максвелла. 

\begin{gather}
    \nabla \cdot E = \frac{\rho}{\epsilon_0} \\
    \nabla \times E = {-\frac{\partial B}{\partial t}} \\
    \nabla \cdot B = 0 \\
    \nabla \times B = \mu_0 (J + \epsilon_0 \frac{\partial E}{\partial t})
\end{gather}



По существующим оценкам, минимальное количество пирамидальных нейронов,
необходимое для создания измеримого за пределами головы поля для МЭГ составляет $\approx$
% TODO: find in Hamalainen <01-02-18, yourname> %
А для ЭЭГ --- 
% TODO: lookup somewhere  <01-02-18, yourname> %
При этом размер участка коры, соответствующий такому количеству нейронов составляет ???,
а источник и сток заряженных частиц разнесены на расстояние порядка ???. По отношению
к характерному расстоянию до сенсоров размеры локальных
источников суммарного тока малы и могут считаться точечными.
Для моделирования таких точечных источников тока на коре вводят понятие \emph{токового диполя}.

Под токовым диполем понимают такой источник тока, у которого сток и исток разнесены на пренебрежимо малое расстояние.
Токовый диполь характеризуется тремя координатами, задающими его положение в пространстве, а также дипольным моментом~---
вектором, характеризующим величину и направление тока.

Чтобы построить порождающую модель данных, в парадигме неинвазивных МЭЭГ измерений, нам

Токовым диполем назвается источник тока, размеры которого пренебрежимо 

\section{Постановка задачи оценки фазовой синхронности по неинвазивным измерениям} \label{sect1_1}

% Мы можем сделать \textbf{жирный текст} и \textit{курсив}.

Рассмотрим типичную постановку эксперимента в ЭЭГ/МЭГ парадигме.
Пусть, было записано $K$ эпох гомогенной электрофизической
активности продолжительностью $\Delta t$ с помощью энцефалографа, имеющего $m$ сенсоров.
Далее, допустим, что имеется информация об анатомии мозга испытуемого (этого достаточно
использовать стандартную анатомическую модель мозга,
но для приложений предпочтительнее иметь индивидуальный МРТ снимок).
Последнее допущение позволяет нам рассмотреть пространство источников --- сетку,
состоящую из $n$ точек на коре и аппроксимирующую поверхность мозга испытуемого (\ref{fig:src_space}).
Решая так называемую прямую задачу [2], мы можем осуществить отображение $n$ точек пространства
источников в $m$-мерное пространство сенсоров с оператором отображения $\mathbf{G}$, имея в виду, что
обычно $n >> m$, так как для качественной аппроксимации нам нужно намного
больше точек на поверхности мозга, чем сенсоров, регистрирующих мозговую активность.

Оператор $\mathbf{G}$ --- суть решение уравнений Максвелла для точечных источников электромагнитной активности,
расположенных в каждом узле сетки, определяющей конфигурацию источников,
и так как уравнения Максвелла линейны, оператор $\mathbf{G}$ также является линейным \cite{Hamalainen1993}.
Мы также должны учесть влияние шума источники которого располагаются во внешней среде
и который в первом приближении предполагается белым.

В этих предположениях можем записать порождающую модель данных на сенсорах:

\begin{figure}
\centering
\includegraphics[scale=0.3]{../images/brain.png}
\caption{Пример сетки в пространстве источников,
          построенной на основе трехмерной анатомической модели}
\label{fig:src_space}
\end{figure}

\begin{equation}
    \mathbf{x}_k(t) = \mathbf{G} \cdot \mathbf{s}_k(t) + \mathbf{\omega}_k(t),
    \label{gm_ts}
\end{equation}
где $\mathbf{s}_k(t)$ --- $n$-мерный вектор-столбец активаций источников,
$\mathbf{x}_k(t)$ --- $m$-мерный вектор-столбец сигналов на сенсорах,
$t$ --- время, а $\mathbf{G}$ --- $m \times n$ матрица линейного отображения пространства источников в пространство сенсоров.
Индекс $k$ обозначает номер эпохи.
Применим к (\ref{gm_ts}) частотное преобразование. Существует много способов произвести
эту операцию, например, --- вейвлет-преобразование или узкополосная фильтрация
с последующим аналитическим представлением сигнала.
Мы не будем вдаваться в подробности теории частотно-временных преобразований;
для подробного математизированного изложения предмета см.
\cite{Oppenheim1998}, о  применении  частотно-временных преобразований к обработке
электрофизиологических данных можно прочитать в \cite{Freeman}.
Мы только упомянем, что вне зависимости от особенностей выбранного
метода образом частотно-временного преобразования матрицы $\mathbf{X}$ размера $m \times T$
будет комплексный тензор, каждый временной срез которого содержит в себе информацию
о фазовом и амплитудном спектре сигнала в каждый момент времени.
Чтобы упростить вывод, мы зафиксируем одну частоту имея в виду,
что дальнейшие выкладки справедливы и для остальных частот преобразования. В итоге мы можем записать:

\begin{equation}
    \hat{\mathbf{x}}_{k,f_i}(t) = \mathbf{G} \cdot \hat{\mathbf{s}}_{k,f_i}(t) + \hat{\mathbf{\omega}}_{k,f_i}(t),
    \label{gm_timefreq}
\end{equation}
где $\hat{\mathbf{x}}, \hat{\mathbf{s}}, \hat{\mathbf{\omega}}$ --- комплекснозначные образы $\mathbf{x}, \mathbf{s}, \mathbf{\omega}$ соответственно.
Для простоты далее будем опускать нижний индекс $f_i$:

\begin{equation}
    \hat{\mathbf{x}}_k(t) = \mathbf{G} \cdot \hat{\mathbf{s}}_k(t) + \hat{\mathbf{\omega}}_k(t)
    \label{gm_timefreq_no_fi}
\end{equation}

Теперь, если мы для каждой эпохи умножим $\hat{\mathbf{x}}_k(t)$ на его эрмитово сопряжение и усредним результат,
мы получим порождающую модель кросс-спектра на сенсорах:

\begin{gather}
           \langle{\hat{\mathbf{x     }}_k(t) \hat{\mathbf{x}}_k(t)^{\dag}} \rangle_{k=1}^K =
           \langle{(\mathbf{G} \cdot\hat{\mathbf{s}}_k(t) + \hat{\mathbf{\omega}}_k(t))
                                       (\mathbf{G} \cdot\hat{\mathbf{s}}_k(t) + \hat{\mathbf{\omega}}_k(t))^{\dag}}\rangle_{k=1}^K=\nonumber\\
= \mathbf{G}  \cdot \langle{\hat{\mathbf{s     }}_k(t) \hat{\mathbf{s     }}_k(t)^{\dag}} \rangle_{k=1}^K \cdot \mathbf{G}^T +
   \mathbf{G} \cdot \langle{\hat{\mathbf{s     }}_k(t) \hat{\mathbf{\omega}}_k(t)^{\dag}} \rangle_{k=1}^K + \nonumber\\
        +  \langle{\hat{\mathbf{\omega}}_k(t) \hat{\mathbf{s     }}_k(t)^{\dag}} \rangle_{k=1}^K \cdot \mathbf{G}^T +
           \langle{\hat{\mathbf{\omega}}_k(t) \hat{\mathbf{\omega}}_k(t)^{\dag}} \rangle_{k=1}^K,
    \label{gm_cp_ini}
\end{gather}
\\
где оператор $\langle \cdot \rangle_{k=1}^K$ означает усреднение по эпохам.

Так как шум предполагается белым, а сигнал на сенсорах $\hat{\mathbf{s}}_k$ и шум $\hat{\mathbf{\omega}}_k$ взаимно независимыми,
можем заметить, что второй и третий члены уравнения (\ref{gm_cp_ini}) равны нулю, когда число эпох достаточно велико.
Также отметим, что
$\hat{\mathbf{x     }}_k(t) \hat{\mathbf{x     }}_k(t)^{\dag}$,
$\hat{\mathbf{s     }}_k(t) \hat{\mathbf{s     }}_k(t)^{\dag}$ и
$\hat{\mathbf{\omega}}_k(t) \hat{\mathbf{\omega}}_k(t)^{\dag}$
представляют собой внешние произведения комплексно-значных векторов на свои комплексные сопряжения,
и следовательно являются эрмитовыми матрицами, что означает,
что значения, находящиеся на диагоналях этих матриц, принадлежат к области вещественных чисел.
Это свойство, очевидно, сохраняется и после усреднения.
Более того, раз элементы векторов являются комплексными числами, они могут быть представлены в виде
$\hat{\xi}(t) = r(t)\cdot e^{i\phi(t)}$, где $\phi(t)$ соответствует мгновенной фазе сигнала,
а $r(t)$ амплитуде. Следовательно,
$\langle \hat{\xi}_p \hat{\xi}_q^* \rangle = \langle r_p r_q e^{i\Delta\phi} \rangle$ или,
если для иллюстрации мы примем, что амплитуды и фазы независимы
(справедливость последнего является предметом разногласий для электрофизиологических данных \cite{Lachaux1999}, \cite{imcoh}),
мы получим, что
$\langle \hat{\xi}_p \hat{\xi}_q^* \rangle = \langle r_p r_q \rangle \langle e^{i\Delta\phi} \rangle$.

Из последнего соотношения можно сделать несколько выводов.
Во-первых, элементы матрицы кросс-спектра представляют собой степень стабильности
разности фаз $\Delta\phi$ по эпохам.
Так, если разность фаз была достаточно равномерно распределена по всему возможному
интервалу принимаемых значений, то среднее $\langle e^{i\Delta\phi} \rangle$
будет приблизительно равно нулю.
С другой стороны, если разность фаз сохраняется от эпохи к эпохе,
результирующий коэффициент будет отличен от нуля,
что соответствует случаю установления коннективности между сигналами.
Во-вторых, если разность фаз мала,
элементы взаимного спектра могут быть близки к ненулевому вещественному числу.

Введем следующее обозначение для матрицы кросс-спектральной плотности:

\begin{equation}
    \Cp{v} \stackrel{def}{=} \langle{\hat{\mathbf{v}}_k(t) \hat{\mathbf{v}}_k(t)^{\dag}}\rangle_{k=1}^K, \\
    \label{cp_def}
\end{equation}
Используя определение (\ref{cp_def}) и опуская нулевые члены, (\ref{gm_cp_ini})
перепишется в виде
\begin{equation}
    \Cp{x}(t) = \mathbf{G} \Cp{s}(t) \mathbf{G}^T + \Cp{\omega}(t)
    \label{gm_cp_matr}
\end{equation}

Теперь рассмотрим более детально диагональ матрицы $\Cp{s}$.
Как уже было сказано, элементы главной диагонали этой матрицы являются вещественными числами
и они представляют собой значения мощностей сигналов пространства источников,
имеющих частоту $f_i$. В структуре порождающей модели отражен тот факт,
что после отображения оператором из пространства источников в пространство сенсоров
с помощью оператора $\mathbf{G}$ эти мощностные члены будут смешаны с истинной коннективностью,
и так как исходная система уравнений была сильно недоопределена (условие $n >> m$),
разделить сигналы не представляется возможным.
Математически, этим и объясняется эффект протечки сигнала.

Чтобы внести дополнительную ясность, представим себе ситуацию,
когда синхронизация между источниками полностью отсутствует,
но при этом некоторые участки мозга активны.
В такой постановке все элементы матрицы $\Cp{s}$, лежащие вне главной диагонали,
будут равны нулю, но для $\Cp{x}$ это выполняться не будет.
Пары сенсоров, расположенные близко к активным участкам мозга,
будут иметь большие кросс-спектральные коэффициенты,
что приведет к ложному обнаружению коннективности между источниками.

В ранее упомянутом методе ImCoh (в настоящее время, вероятно,
наиболее часто используемом для измерения коннективности)
предлагается рассматривать только мнимые части уравнения (\ref{gm_cp_matr}),
что уберегает нас от негативного эффекта протечки сигнала,
но при этом мы также теряем действительную часть <<хорошего>> сигнала, несущую
информацию о фазовой синхронизации.

\subsection{Проекция}

Для более полного использования информации о фазовой синхронизации, содержащейся в кросс-спектре
мы предлагаем другой подход к устранению эффекта протечки сигнала.
Распишем  произведение матриц $\mathbf{G} \Cp{s} \mathbf{G}^T$ в правой части уравнения (\ref{gm_cp_matr}):

\begin{gather}
    \Cp{x}(t) = \sum\limits_{p=1}^n\sum\limits_{q=1}^n\mathbf{g}_p\mathbf{g}_q^T c_{pq}^{\mathbf{ss}}(t) + \Cp{\omega}(t),
    \label{cp_rhs_expanded}
\end{gather}
где $\mathbf{g}_p$ --- столбец матрицы $\mathbf{G}$, который называют \emph{топографией} источника $p$,
поскольку он определяет, каким образом сигнал, поступающий от источника $p$, будет виден на сенсорах.
Можно заметить, что кросс-спектр на уровне сенсоров представляет собой взвешенную сумму внешних произведений топографий,
взятую с коэффициентами, являющимися элементами кросс-спектра из пространства источников.

\section{Произведение Кронекера}
Векторизуем уравнение (\ref{cp_rhs_expanded}):

\begin{gather}
    vec(\Cp{x}(t)) = \sum\limits_{p=1}^n\sum\limits_{q=1}^n vec(\mathbf{g}_p\mathbf{g}_q^T) c_{pq}^{\mathbf{ss}}(t) + vec(\Cp{\omega}(t))
    \label{cp_rhs_vec}
\end{gather}

Для упрощения записи будем использовать понятие произведения Кронекера.
Произведением Кронекера матриц $A$ и $B$, имеющих размеры $p\times q$ и $r\times s$ соответственно, называется матрица вида

\begin{equation}
    \mathbf{A} \otimes \mathbf{B} \stackrel{def}{=}
    \begin{bmatrix}
        a_{11} \mathbf{B} & a_{12} \mathbf{B} & \dots & a_{1n} \mathbf{B} \\
        a_{21} \mathbf{B} & a_{22} \mathbf{B} & \dots & a_{2n} \mathbf{B} \\
        \vdots            & \vdots            & \dots & \vdots            \\
        a_{m1} \mathbf{B} & a_{m2} \mathbf{B} & \dots & a_{mn} \mathbf{B}
        \label{kron_def}
     \end{bmatrix}
\end{equation}

Произведение Кронекера является билинейной ассоциативной операцией:

\begin{gather}
     \mathbf{A} \otimes (\mathbf{B} + \mathbf{C}) = \mathbf{A} \otimes \mathbf{B} + \mathbf{A} \otimes \mathbf{C} \\
    (\mathbf{A} + \mathbf{B}) \otimes \mathbf{C} = \mathbf{A} \otimes \mathbf{C} + \mathbf{B} \otimes \mathbf{C} \\
    \alpha(\mathbf{A} \otimes \mathbf{B}) = (\alpha\mathbf{A}) \otimes \mathbf{B} = \mathbf{A} \otimes (\alpha\mathbf{B}) \\
    \mathbf{A} \otimes(\mathbf{B} \otimes \mathbf{C}) =
   (\mathbf{A} \otimes \mathbf{B})\otimes \mathbf{C} =
    \mathbf{A} \otimes \mathbf{B} \otimes \mathbf{C}
\end{gather}

Заметим также, что произведение Кронекера не является симметричным: $\mathbf{A} \otimes \mathbf{B} \neq \mathbf{B} \otimes \mathbf{A}$.
Приведем другие полезные соотношения:

\begin{gather}
    (\mathbf{A} \otimes \mathbf{B})^T = \mathbf{A}^T \otimes \mathbf{B}^T \\
    (\mathbf{A} \otimes \mathbf{B}) (\mathbf{C} \otimes \mathbf{D}) = (\mathbf{A} \mathbf{B}) \otimes (\mathbf{C} \mathbf{D})
\end{gather}

Существует особо интересное для нас свойство произведения Кронекера, связывающее его с процедурой векторизации.
Для матриц $\mathbf{A}$, $\mathbf{B}$, $\mathbf{C}$ справедливо (доказательство см. в [10]):

\begin{equation}
    vec(\mathbf{A} \mathbf{B} \mathbf{C}) = (\mathbf{C}^T \otimes \mathbf{A}) vec(\mathbf{C})
\end{equation}

Отметим, что в нашем случае приведенное выражение принимает самую простую форму:

\begin{gather}
    vec[\mathbf{g}_p \mathbf{g}_q^T] = vec\left[
        \begin{pmatrix}
            g_p^1 \\
            \vdots \\
            g_p^m
        \end{pmatrix}
    \cdot 1 \cdot
    \begin{pmatrix}
        g_q^1 & \dots & g_q^m
    \end{pmatrix}
    \right] = %\nonumber \\
    \begin{pmatrix}
        g_q^1 \\
        \vdots \\
        g_q^m
    \end{pmatrix}
    \otimes
    \begin{pmatrix}
        g_p^1 \\
        \vdots \\
        g_p^m
    \end{pmatrix}
    \cdot
    vec(1) =
    \mathbf{g}_q \otimes \mathbf{g}_p,
\end{gather}

где $\mathbf{g}_q \otimes \mathbf{g}_p$ представляет собой вектор-столбец размера $m^2 \times 1$.
Перепишем выражение (\ref{cp_rhs_vec}), используя новые обозначения:

\begin{equation}
    vec(\Cp{x}(t)) = \sum\limits_{p=1}^n\sum\limits_{q=1}^n \mathbf{g}_q\otimes \mathbf{g}_p \cdot c_{pq}^{\mathbf{ss}}(t) + vec(\Cp{\omega}(t))
    \label{cp_rhs_kron}
\end{equation}
Теперь можно видеть, что векторизованный кросс-спектр на уровне сенсоров представлен линейной
комбинацией векторов $\mathbf{g}_q \otimes \mathbf{g}_p$ в $m^2$-мерном векторном пространстве.
Назовем эти векторы \emph{2-топографиями}.
Нам уже известно, что эффект протечки сигнала, от которого необходимо избавиться,
обусловлен 2-топографиями особого вида $\mathbf{g}_p \otimes \mathbf{g}_p$ (всего $n$ векторов),
конкретный вид которых нам задан через оператор $\mathbf{G}$.
Следовательно, мы можем спроецировать выражение (\ref{cp_rhs_kron}) ортогонально линейному пространству,
натянутому на 2-топографии источников протечки сигнала.

\subsection{Построение оператора проецирования}
Прежде чем мы начнем построение оператора ортогональной проекции от подпространства протечки сигнала,
необходимо понять, как соотносится подпространство протечки сигнала с линейными оболочками
2-топографий действительной и мнимой частей порождающей модели кросс-спектра на сенсорах.

Во-первых, выделим в уравнении (\ref{cp_rhs_kron}) действительную и мнимую части.
Заметим, что так как матрица $\Cp{s}$ является эрмитовой,
$c^{\mathbf{ss}}_{pq} = \overline{c^{\mathbf{ss}}_{qp}}$ (верхняя черта обозначает комплексное сопряжение):

\begin{gather}
                      \sum\limits_{p=1}^n\sum\limits_{q=1}^n \mathbf{g}_q\otimes \mathbf{g}_p \cdot c_{pq}^{\mathbf{ss}}(t) =
             Re\left(\sum\limits_{p,q=1}^{n,n} \mathbf{g}_q\otimes \mathbf{g}_p \cdot c_{pq}^{\mathbf{ss}}(t)\right) +
     i \cdot Im\left(\sum\limits_{p,q=1}^{n,n} \mathbf{g}_q\otimes \mathbf{g}_p \cdot c_{pq}^{\mathbf{ss}}(t)\right) = \nonumber \\
           = \sum\limits_{p\leq q}^{n,n} (\mathbf{g}_q\otimes \mathbf{g}_p + \mathbf{g}_p\otimes \mathbf{g}_q)
                                                                                    Re\left(c_{pq}^{\mathbf{ss}}(t)\right) +
     i \cdot \sum\limits_{p<q}^{n,n} (\mathbf{g}_q\otimes \mathbf{g}_p - \mathbf{g}_p\otimes \mathbf{g}_q)
                                                                                    Im\left(c_{pq}^{\mathbf{ss}}(t)\right)
    \label{cp_re_im}
\end{gather}

Отметим изменения в индексах суммирования.

Для удобства обозначим линейное пространство, натянутое на 2-топографии, ответственные за протечку сигнала, как
$S_{SL}$, а линейную оболочку 2-топографий мнимой части --- $S_{Im}$.

Из уравнения (\ref{cp_re_im}) видно, что 2-топографии действительной и мнимой частей устроены по-разному,
а именно, --- векторы $\mathbf{g}_q \otimes \mathbf{g}_p + \mathbf{g}_p \otimes \mathbf{g}_q$ являются симметричными,
тогда как 2-топографии мнимых частей $\mathbf{g}_q \otimes \mathbf{g}_p - \mathbf{g}_p \otimes \mathbf{g}_q$
антисимметричны по индексам $p, q$.
Нас интересует, как это структурное отличие проявляется во взаимосвязи подпространств $S_{Re}$ и $S_{Im}$ с
подпространством протечки сигнала $S_{VC}$.
Покажем, что  2-топографии мнимой части ортогональны векторам, на которые натянуто подпространство объемной проводимости:
\begin{gather}
    (\mathbf{g}_s \otimes \mathbf{g}_s)^T(\mathbf{g}_q \otimes \mathbf{g}_p - \mathbf{g}_p \otimes \mathbf{g}_q) =
        (\mathbf{g}_s^T \otimes \mathbf{g}_s^T)(\mathbf{g}_q \otimes \mathbf{g}_p) -
        (\mathbf{g}_s^T \otimes \mathbf{g}_s^T)(\mathbf{g}_p \otimes \mathbf{g}_q) = \nonumber \\
       =(\mathbf{g}_s^T \mathbf{g}_q \otimes \mathbf{g}_s^T \mathbf{g}_p -
         \mathbf{g}_s^T \mathbf{g}_p \otimes \mathbf{g}_s^T \mathbf{g}_q) \stackrel{*}{=}
        (\mathbf{g}_s^T \mathbf{g}_p \mathbf{g}_s^T \mathbf{g}_q -
         \mathbf{g}_s^T \mathbf{g}_p \mathbf{g}_s^T \mathbf{g}_q) = 0
         \label{vc_ort_im}
\end{gather}

Равенство $*$ сохраняется, так как $\mathbf{g}^T_s \mathbf{g}_q$ и $\mathbf{g}_s^T \mathbf{g}_p$ являются скалярными величинами,
и мы можем опустить операцию ``$\otimes$'' и поменять местами множители.
Из (\ref{vc_ort_im}) можно видеть,
что подпространство объемной проводимости ортогонально мнимой части подпространства.
Для действительной части такое соотношение не сохраняется:
\begin{gather}
    (\mathbf{g}_s \otimes \mathbf{g}_s)^T(\mathbf{g}_q \otimes \mathbf{g}_p + \mathbf{g}_p \otimes \mathbf{g}_q) =
        (\mathbf{g}_s^T \otimes \mathbf{g}_s^T)(\mathbf{g}_q \otimes \mathbf{g}_p) +
        (\mathbf{g}_s^T \otimes \mathbf{g}_s^T)(\mathbf{g}_p \otimes \mathbf{g}_q) = \nonumber \\
       =(\mathbf{g}_s^T \mathbf{g}_q \otimes \mathbf{g}_s^T \mathbf{g}_p +
         \mathbf{g}_s^T \mathbf{g}_p \otimes \mathbf{g}_s^T \mathbf{g}_q) =
        2\langle\mathbf{g}_s, \mathbf{g}_p\rangle \langle\mathbf{g}_s, \mathbf{g}_q\rangle
         \label{vc_ort_re}
\end{gather}

После проведенных операций легко увидеть, что проекция ортогонально подпространству протечки сигнала
оказывает влияние на подпространство действительной части кросс-спектра на источниках.
Следовательно, нужно добиться того, чтобы протечка сигнала была удалена из данных
насколько это возможно с учетом минимального воздействия на подпространство
действительной части кросс-спектра (см.рис.~\ref{fig:subspaces}).
Для достижения этой цели необходимо уменьшить размерность подпространства
объемной проводимости неким оптимальным способом.

\begin{figure}[htbp]
\centering
\includegraphics[width=12cm]{./images/SetsReImVC.jpg}
\caption{Взаимосвязь подпространств для кросс-спектра на уровне сенсоров}
\medskip
\small
Подпространство протечки сигнала $S_{SL}$ и подпространство действительной части кросс-спектра $S_{\Re}$
имеют непустое пересечение. Кроме того, оба этих подпространства ортогональны подпространству мнимой
части кросс-спектра $S_{\Im}$.
Пересечение $S_{SL}$ с $S_{\Re}$ содержит вклад как от протечки сигнала,
так и от истинно взаимодействующих источников, расположенных близко друг к другу и характеризующихся малой разностью фаз.
\label{fig:subspaces}
\end{figure}%
Имея в виду все вышеперечисленное, вернемся к построению проектора.
Рассмотрим матрицу, составленную из вектор-столбцов, образующих подпространство протечки сигнала:

\begin{equation}
    \mathbf{F} =
    \begin{bmatrix}
        |                                 & |                                 &       & |                                 \\
        \mathbf{g}_1 \otimes \mathbf{g}_1 & \mathbf{g}_2 \otimes \mathbf{g}_2 & \dots & \mathbf{g}_n \otimes \mathbf{g}_n \\
        |                                 & |                                 &       & |
    \end{bmatrix}
\end{equation}

Произведем сингулярное разложение матрицы $\mathbf{F}$ \cite{Golub1996}.

\begin{equation}
    \mathbf{F} = \mathbf{USV}^T
    =
    \begin{bmatrix}
        |            & |            &        & |       \\
        \mathbf{u}_1 & \mathbf{u}_2 & \dots  & \mathbf{u}_{m^2} \\
        |            & |            &        & |
    \end{bmatrix}
    % S
    % \begin{pmatrix}
    %   \lambda_1 & 0         & \dots   & 0             & 0 & \dots & 0 \\
    %   0         & \lambda_2 & \dots   & \vdots        & 0 & \dots & 0 \\
    %   \vdots    &           & \ddots  & 0             & 0 & \dots & 0 \\
    %   0         & \dots     & \dots   & \lambda_{m^2} & 0 & \dots & 0
    % \end{pmatrix}
    \begin{pmatrix}
        \lambda_1 & 0         & \dots    \\
        0         & \lambda_2 & \dots    \\
        \vdots    &           & \ddots
    \end{pmatrix}
    % Diag(\lambda_1, \dots, \lambda_{m^2})
    \begin{bmatrix}
        - & \mathbf{v}_1 & - \\
        - & \mathbf{v}_2 & - \\
          & \dots        &   \\
        - & \mathbf{v}_n & -
    \end{bmatrix}
\end{equation}
\\
В соответствии со свойствами сингулярного разложения, первые $r$ колонок матрицы $\mathbf{U}$
образуют ортонормальный базис $r$-мерного линейного пространства, являющегося лучшим $r$-мерным приближением $n$-мерного
подпространства протечки сигнала. Используем эти $r$ векторов для построения проектора с уменьшенным рангом:

\begin{gather}
    \mathbf{U}_r =
    \begin{bmatrix}
        |            & |            &        & |       \\
        \mathbf{u}_1 & \mathbf{u}_2 & \dots  & \mathbf{u}_r \\
        |            & |            &        & |
    \end{bmatrix};\\
    \mathbf{P}_r = \mathbf{I} - \mathbf{U}_r \mathbf{U}_r^T
 \end{gather}
Итак, мы построили оператор проекции ортогонально подпространству протечки сигнала $\mathbf{P}_r$
с сокращенным рангом $r$.
Умножение уравнения (\ref{cp_rhs_kron}) на этот оператор приводит к тому, что  из порождающей
модели кросс-спектра на уровне сенсоров частично удаляются члены ответственные за эффект протечки сигнала;
параметр $r$ при этом определяет баланс между желаемым уровнем очистки от протечки сигнала и
воздействием проектора на действительную часть кросс-спектра.

Окончательно, выражение для кросс-спектра на уровне сенсоров после проекции от протечки сигнала
запишется в виде:

\begin{equation}
    vec(\Cp{x})^\perp = \mathbf{P}_r vec(\Cp{x}) =  \sum\limits_{p=1}^n\sum\limits_{q=1}^n \mathbf{P}_r \mathbf{g}_q\otimes \mathbf{g}_p \cdot c_{pq}^{\mathbf{ss}}(t) + \mathbf{P}_r vec(\Cp{\omega}(t))
    \label{cp_final}
\end{equation}

Элементы полученного таким образом векторизованного кросс-спектра $vec(\Cp{x})^\perp$ теперь могут быть
использованы для оценки коннективностей как на уровне сенсоров, так и в источниках.

\subsection{Модели со свободной ориентацией диполя}
С точки зрения анатомии каждая топография прямой модели $\mathbf{G}$
представляет собой распределение электромагнитного поля,
порождаемого так называемыми первичными токами, то есть токами,
текущими через апикальные дендриты кортикальных пирамидальных нейронов.
Так как апикальные дендриты расположены перпендикулярно к кортикальной мантии,
первичные токи по отношению к кортикальной мантии также имеют нормальную ориентацию.
Следовательно, точность прямой модели напрямую зависит от точности оценки вектора нормали
к поверхности коры, а значит и от количества точек, используемых для аппроксимации поверхности коры.
Вместе с тем, хотя современное моделирование с использованием метода магнитно-резонансной
томографии позволяет получать весьма детальную реконструкцию мозга с размером аппроксимирующих сеток
порядка нескольких сотен тысяч узлов, использование столь подробных сеток приводит к значительному
ухудшению производительности алгоритмов, работающих в пространстве источников, вследствие высоких затрат
по памяти и вычислительному времени при работе с большими массивами данных.

По этой причине использование разреженных сеток со сравнительно небольшим числом узлов стало
общепринятой практикой. Как уже отмечалось выше, недостаток такого подхода состоит в том, что
при прореживании сетки эффективная ориентация локальной нормали к коре становится неопределенной.

Неопределенность появляется из-за того, что после разрежения размер области на коре, соответствующей отдельно
взятому узлу сетки, возрастает, и так как каждая такая область характеризуется в общем случае
переменной кривизной, эффективная ориентация токового диполя, находящегося внутри отдельно взятой области аппроксимации,
будет зависеть от того, в какой именно части области находился диполь в тот или иной момент записи.

Частично справиться с этим эффектом позволяют модели, со \emph{свободной ориентацей диполя},
в которых эффективная ориентация становится дополнительным параметром, который необходимо оценить из данных~\cite{Lin2006}.

Для учета свободной ориентации следует представить топографию в точке $p$ коры в виде линейной
комбинации трех ортогональных друг к другу векторов топографии, размещенных в одной точке:
\begin{equation}
    \mathbf{g}_p = \mathbf{g}_p^x \xi + \mathbf{g}_p^y \eta + \mathbf{g}_p^z \zeta = [\mathbf{g}_p^x, \mathbf{g}_p^y, \mathbf{g}_p^z] \left(
    \begin{array}{ccc}
        \xi \\
        \eta \\
        \zeta
    \end{array}
    \right)
    \label{loose_or}
\end{equation}

В случае МЭГ измерений, так как магнитное поле от токового диполя с радиальной ориентацией вне сферического проводника равно нулю,
введенная тройка векторов может быть заменена парой диполей в плоскости, перпендикулярной радиальному направлению для каждого узла.
Следовательно, уравнение (\ref{loose_or}) перепишется для МЭГ в виде

\begin{equation}
    \mathbf{g}_p = \mathbf{g}_p^x \xi + \mathbf{g}_p^y \eta = [\mathbf{g}_p^x, \mathbf{g}_p^y] \left(
    \begin{array}{ccc}
        \xi \\
        \eta
    \end{array}
    \right)
    \label{loose_or_meg}
\end{equation}

Соответственно изменятся выражения и для 2-топографий протечки сигнала:

\begin{gather}
    \mathbf{g}_p \otimes \mathbf{g}_p = (\mathbf{g}_p^x \xi
                                      + \mathbf{g}_p^y \eta) \otimes (\mathbf{g}_p^x \xi
                                      + \mathbf{g}_p^y \eta) = \nonumber \\
                                      = \mathbf{g}_p^x \otimes \mathbf{g}_p^x \xi^2
                                      + \mathbf{g}_p^x \otimes \mathbf{g}_p^y \xi \eta
                                      + \mathbf{g}_p^y\otimes  \mathbf{g}_p^x \eta \xi
                                      + \mathbf{g}_p^y \otimes \mathbf{g}_p^y \eta^2 = \nonumber \\
                                      = [\mathbf{g}_p^x \otimes \mathbf{g}_p^x,
                                         \mathbf{g}_p^x \otimes \mathbf{g}_p^y
                                      + \mathbf{g}_p^y \otimes \mathbf{g}_p^x,
                                        \mathbf{g}_p^y \otimes \mathbf{g}_p^y]
\left( \begin{array}{ccc}
\xi^2 \\
\xi \eta \\
\eta^2
\end{array}
\right)
\end{gather}

Можно заметить, что 2-топографии объемной проводимости теперь принадлежат линейной оболочке трех векторов,
а именно --- $\mathbf{g}_p^x \otimes \mathbf{g}_p^x$, $\mathbf{g}_p^x \otimes \mathbf{g}_p^y + \mathbf{g}_p^y \otimes \mathbf{g}_p^x$ и $\mathbf{g}_p^y \otimes \mathbf{g}_p^y$.
Разумеется, представленная таким образом 2-топография протечки сигнала зависит только от параметра $\theta_p$ --- угла
между эффективной ориентацией топографии $\mathbf{g}_p$ и ее $х$-компоненты --- через $\xi = sin(\theta_p)$ и $\eta=cos(\theta_p)$:

\begin{equation*}
    \mathbf{g}_p \otimes \mathbf{g}_p =[\mathbf{g}_p^x \otimes \mathbf{g}_p^x, \mathbf{g}_p^x \otimes \mathbf{g}_p^y + \mathbf{g}_p^y \otimes \mathbf{g}_p^x, \mathbf{g}_p^y \otimes \mathbf{g}_p^y]
    \left( \begin{array}{ccc}
    cos(\theta_p)^2 \\
    cos(\theta_p) sin(\theta_p) \\
    sin(\theta_p)^2
    \end{array}
    \right)
\end{equation*}
Но это однопараметрическое семейство векторов не может быть эффективно сведено к линейному векторному
пространству с размерностью меньше 3 для построения соответствующего проектора,
а значит мы должны добавить все три 2-топографии источника $p$ в матрицу $F$:

\begin{equation}
    \mathbf{F} =
    \begin{bmatrix}
        \mathbf{g}_1^x \otimes \mathbf{g}_1^x, &
        \mathbf{g}_1^x \otimes \mathbf{g}_1^y + \mathbf{g}_1^y \otimes \mathbf{g}_1^x, &
        \mathbf{g}_2^x \otimes \mathbf{g}_2^x, &
        \dots, & \mathbf{g}_n^y \otimes \mathbf{g}_n^y \\
    \end{bmatrix}
\end{equation}

%\newpage
%========================================================================================================

\section{Ссылки} \label{sect1_2}
Сошлёмся на библиографию.
Одна ссылка: \cite[с.~54]{Sokolov}\cite[с.~36]{Gaidaenko}.
Две ссылки: \cite{Sokolov,Gaidaenko}.
Много ссылок: %\cite[с.~54]{Lermontov,Management,Borozda} % такой «фокус» вызывает biblatex warning относительно опции sortcites, потому что неясно, к какому источнику относится уточнение о страницах, а bibtex об этой проблеме даже не предупреждает
\cite{Lermontov,Management,Borozda,Marketing,Constitution,FamilyCode,Gost.7.0.53,Razumovski,Lagkueva,Pokrovski,Sirotko,Lukina,Methodology,Encyclopedia,Nasirova,Berestova,Kriger}.
И~ещё немного ссылок:
\cite{Article,Book,Booklet,Conference,Inbook,Incollection,Manual,Mastersthesis,Misc,Phdthesis,Proceedings,Techreport,Unpublished}.
\cite{medvedev2006jelektronnye, CEAT:CEAT581, doi:10.1080/01932691.2010.513279,Gosele1999161,Li2007StressAnalysis, Shoji199895,test:eisner-sample,AB_patent_Pomerantz_1968,iofis_patent1960}

%Попытка реализовать несколько ссылок на конкретные страницы для стандартной реализации:[\citenum{Sokolov}, с.~54; \citenum{Gaidaenko}, с.~36].

%Несколько источников мультицитата (только в biblatex)
%\cites[vii--x, 5, 7]{Sokolov}[v"--~x, 25, 526]{Gaidaenko} поехали дальше

Ссылки на собственные работы:~\cite{vakbib1, confbib1}

Сошлёмся на приложения: Приложение \ref{AppendixA}, Приложение \ref{AppendixB2}.

Сошлёмся на формулу: формула \eqref{eq:equation1}.

Сошлёмся на изображение: рисунок \ref{img:knuth}.

%\newpage
%============================================================================================================================

\section{Формулы} \label{sect1_3}

Благодаря пакету \textit{icomma}, \LaTeX~одинаково хорошо воспринимает в качестве десятичного разделителя и запятую ($3,1415$), и точку ($3.1415$).

\subsection{Ненумерованные одиночные формулы} \label{subsect1_3_1}

Вот так может выглядеть формула, которую необходимо вставить в строку по тексту: $x \approx \sin x$ при $x \to 0$.

А вот так выглядит ненумерованая отдельностоящая формула c подстрочными и надстрочными индексами:
\[
(x_1+x_2)^2 = x_1^2 + 2 x_1 x_2 + x_2^2
\]

При использовании дробей формулы могут получаться очень высокие:
\[
  \frac{1}{\sqrt{2}+
  \displaystyle\frac{1}{\sqrt{2}+
  \displaystyle\frac{1}{\sqrt{2}+\cdots}}}
\]

В формулах можно использовать греческие буквы:
\[
\alpha\beta\gamma\delta\epsilon\varepsilon\zeta\eta\theta\vartheta\iota\kappa\lambda\\mu\nu\xi\pi\varpi\rho\varrho\sigma\varsigma\tau\upsilon\phi\varphi\chi\psi\omega\Gamma\Delta\Theta\Lambda\Xi\Pi\Sigma\Upsilon\Phi\Psi\Omega
\]

\def\slantfrac#1#2{ \hspace{3pt}\!^{#1}\!\!\hspace{1pt}/
  \hspace{2pt}\!\!_{#2}\!\hspace{3pt}
} %Макрос для красивых дробей в строчку (например, 1/2)
Для красивых дробей (например, в индексах) можно добавить макрос
\verb+\slantfrac+ и писать $\slantfrac{1}{2}$ вместо $1/2$.
%\newpage
%============================================================================================================================

\subsection{Ненумерованные многострочные формулы} \label{subsect1_3_2}

Вот так можно написать две формулы, не нумеруя их, чтобы знаки равно были строго друг под другом:
\begin{align}
  f_W & =  \min \left( 1, \max \left( 0, \frac{W_{soil} / W_{max}}{W_{crit}} \right)  \right), \nonumber \\
  f_T & =  \min \left( 1, \max \left( 0, \frac{T_s / T_{melt}}{T_{crit}} \right)  \right), \nonumber
\end{align}

Выровнять систему ещё и по переменной $ x $ можно, используя окружение \verb|alignedat| из пакета \verb|amsmath|. Вот так:
\[
    |x| = \left\{
    \begin{alignedat}{2}
        &&x, \quad &\text{eсли } x\geqslant 0 \\
        &-&x, \quad & \text{eсли } x<0
    \end{alignedat}
    \right.
\]
Здесь первый амперсанд (в исходном \LaTeX\ описании формулы) означает выравнивание по~левому краю,
второй "--- по~$ x $, а~третий "--- по~слову <<если>>. Команда \verb|\quad| делает большой горизонтальный пробел.

Ещё вариант:
\[
    |x|=
    \begin{cases}
    \phantom{-}x, \text{если } x \geqslant 0 \\
    -x, \text{если } x<0
    \end{cases}
\]

Кроме того, для  нумерованых формул \verb|alignedat|  делает вертикальное
выравнивание номера формулы по центру формулы. Например,  выравнивание компонент вектора:
\begin{equation}
 \label{eq:2p3}
 \begin{alignedat}{2}
{\mathbf{N}}_{o1n}^{(j)} = \,{\sin} \phi\,n\!\left(n+1\right)
         {\sin}\theta\,
         \pi_n\!\left({\cos} \theta\right)
         \frac{
               z_n^{(j)}\!\left( \rho \right)
              }{\rho}\,
           &{\boldsymbol{\hat{\mathrm e}}}_{r}\,+   \\
+\,
{\sin} \phi\,
         \tau_n\!\left({\cos} \theta\right)
         \frac{
            \left[\rho z_n^{(j)}\!\left( \rho \right)\right]^{\prime}
              }{\rho}\,
            &{\boldsymbol{\hat{\mathrm e}}}_{\theta}\,+   \\
+\,
{\cos} \phi\,
         \pi_n\!\left({\cos} \theta\right)
         \frac{
            \left[\rho z_n^{(j)}\!\left( \rho \right)\right]^{\prime}
              }{\rho}\,
            &{\boldsymbol{\hat{\mathrm e}}}_{\phi}\:.
\end{alignedat}
\end{equation}

Ещё об отступах. Иногда для лучшей <<читаемости>> формул полезно
немного исправить стандартные интервалы \LaTeX\ с учётом логической
структуры самой формулы. Например в формуле~\ref{eq:2p3} добавлен
небольшой отступ \verb+\,+ между основными сомножителями, ниже
результат применения всех вариантов отступа:
\begin{align*}
\backslash! &\quad f(x) = x^2\! +3x\! +2 \\
  \mbox{по-умолчанию} &\quad f(x) = x^2+3x+2 \\
\backslash, &\quad f(x) = x^2\, +3x\, +2 \\
\backslash{:} &\quad f(x) = x^2\: +3x\: +2 \\
\backslash; &\quad f(x) = x^2\; +3x\; +2 \\
\backslash \mbox{space} &\quad f(x) = x^2\ +3x\ +2 \\
\backslash \mbox{quad} &\quad f(x) = x^2\quad +3x\quad +2 \\
\backslash \mbox{qquad} &\quad f(x) = x^2\qquad +3x\qquad +2
\end{align*}


Можно использовать разные математические алфавиты:
\begin{align}
\mathcal{ABCDEFGHIJKLMNOPQRSTUVWXYZ} \nonumber \\
\mathfrak{ABCDEFGHIJKLMNOPQRSTUVWXYZ} \nonumber \\
\mathbb{ABCDEFGHIJKLMNOPQRSTUVWXYZ} \nonumber
\end{align}

Посмотрим на систему уравнений на примере аттрактора Лоренца:

\[
\left\{
  \begin{array}{rl}
    \dot x = & \sigma (y-x) \\
    \dot y = & x (r - z) - y \\
    \dot z = & xy - bz
  \end{array}
\right.
\]

А для вёрстки матриц удобно использовать многоточия:
\[
\left(
  \begin{array}{ccc}
    a_{11} & \ldots & a_{1n} \\
    \vdots & \ddots & \vdots \\
    a_{n1} & \ldots & a_{nn} \\
  \end{array}
\right)
\]


%\newpage
%============================================================================================================================
\subsection{Нумерованные формулы} \label{subsect1_3_3}

А вот так пишется нумерованая формула:
\begin{equation}
  \label{eq:equation1}
  e = \lim_{n \to \infty} \left( 1+\frac{1}{n} \right) ^n
\end{equation}

Нумерованых формул может быть несколько:
\begin{equation}
  \label{eq:equation2}
  \lim_{n \to \infty} \sum_{k=1}^n \frac{1}{k^2} = \frac{\pi^2}{6}
\end{equation}

Впоследствии на формулы (\ref{eq:equation1}) и (\ref{eq:equation2}) можно ссылаться.

Сделать так, чтобы номер формулы стоял напротив средней строки, можно, используя окружение \verb|multlined| (пакет \verb|mathtools|) вместо \verb|multline| внутри окружения \verb|equation|. Вот так:
\begin{equation} % \tag{S} % tag - вписывает свой текст
  \label{eq:equation3}
    \begin{multlined}
        1+ 2+3+4+5+6+7+\dots + \\
        + 50+51+52+53+54+55+56+57 + \dots + \\
        + 96+97+98+99+100=5050
    \end{multlined}
\end{equation}

Используя команду \verb|\labelcref| из пакета \verb|cleveref|, можно
красиво ссылаться сразу на несколько формул
(\labelcref{eq:equation1,eq:equation3,eq:equation2}), даже перепутав
порядок ссылок \verb|(\labelcref{eq:equation1,eq:equation3,eq:equation2})|.

